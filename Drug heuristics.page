---
description: Bostrom's evolutionary heuristics & how they apply to nootropics
...

People discussion human-enhancement (especially [transhumanists](!Wikipedia)) have long recognized a pessimistic observation, sometimes dubbed "Algernon's law" or the "Algernon principle".

# Algernon's law

The famous story _[Flowers for Algernon](!Wikipedia)_ postulates surgery which triples the IQ score of the retarded protagonist - but which comes with the devastating side-effects of the gain being both temporary and sometimes fatal. [Eliezer Yudkowsky](!Wikipedia) expands the thought out in his essay ["Algernon's Law"](http://web.archive.org/web/200102021712/http://sysopmind.com/algernon.html), stating it as:

> "Any simple major enhancement to human intelligence is a net evolutionary disadvantage."

The lesson is that Mother Nature know best. Or alternately, [TANSTAAFL](!Wikipedia): "there ain't no such thing as a [free lunch](!Wikipedia)". Trade-offs are endemic in evolutionary biology. Often, if you use a drug or surgery to optimize something, you will discover penalties elsewhere. If you try to stop aging, you might find that you have just encouraged cancer; if your immune system goes all-out against disease, you either deplete your energetic and chemical reserves[^Humphrey] or risk autoimmune disorders; if you try to enhance attention with an amphetamine, you destroy creativity, or if the amphetamines reduce sleep, you damage memory consolidation or peripheral awareness[^sleep]; or improving memory also increases sensitivity to pain[^doogie] and so on. "Hardly any man is clever enough to know all the evil he does."^[[François de La Rochefoucauld](!Wikipedia), _Maximes_ 269]

[^Humphrey]: ["The Evolved Self-Management System"](http://edge.org/conversation/the-evolved-self-management-system), [Nicholas Humphrey](!Wikipedia):

    > "...Some years ago I drew attention to the "paradox of [placebos](!Wikipedia)", a paradox that must strike any evolutionary biologist who thinks about it. It's this. When a person's health improves under the influence of placebo medication, then, as we've noted already, this has to be a case of "self-cure". But if people have the capacity to heal themselves by their own efforts, why not get on with it as soon as needed? Why wait for permission—from a sugar pill, a witch doctor—that it's time to get better?
    >
    > Presumably the explanation must be that self-cure has *costs* as well as benefits. What kind of costs are these? Well, actually they're fairly obvious. Many of the illnesses we experience, like pain, fever and so on, are actually defenses which are designed to stop us from getting into more trouble than we're already in. So "curing" ourselves of these defenses can indeed cost us down the line. Pain reduces our mobility, for example, and stops us from harming ourselves further; so, relieving ourselves of pain is actually quite risky. Fever helps kill bacterial parasites by raising body temperature to a level they can't tolerate; so again, curing ourselves of fever [is risky](http://findarticles.com/p/articles/mi_hb4384/is_3_38/ai_n29083511/). Vomiting gets rid of toxins; so suppressing vomiting is risky. The same goes for the deployment of the immune system. Mounting an immune response is energetically expensive. Our metabolic rate rises 15% or so, even if we're just responding to a common cold. What's more, when we make antibodies we use up rare nutrients that will later have to be replaced.
    >
    > Given these costs, it becomes clear that immediate self-cure from an occurrent illness is not always a wise thing to do. In fact there will be circumstances when it would be best to *hold back* from deploying particular healing measures because the anticipated benefits are not likely to exceed the anticipated costs. In general it will be wise to err on side of caution, *to play safe*, not to let down our defenses such as pain or fever until we see signs that the danger has passed, not to use up our stock of ammunition against parasites until we know we're in relatively good shape and there's not still worse to come. Healing ourselves involves—or ought to involve—a judgment call...There's plenty of evidence that we have just such a system at work overseeing our health. For example, in winter, we are cautious about deploying our immune resources. That's why a cold lasts much longer in winter than it does in summer. It's not because we're cold, it's because our bodies, based on deep evolutionary history reckon that it's not so safe to use our immune resources in winter, as it would be in summer. There's experimental confirmation of this in animals. Suppose a hamster is injected with bacteria which makes it sick—but in one case the hamster is on an artificial day/night cycle that suggests it's summer; in the other case it's on a cycle that suggests it's winter. If the hamster is tricked into thinking it's summer, it throws everything it has got against the infection and recovers completely. If it thinks it's winter then it just mounts a holding operation, as if it's waiting until it knows it's safe to mount a full-scale response. The hamster "thinks" this or that?? No, of course it doesn't think it consciously—the light cycle acts as a subconscious prime to the hamster's health management system."

    Humphrey also goes on to point out that exploiting the placebo effect satisfies one of Bostrom's [EOC criteria](#loopholes) (which we haven't discussed yet):

    > "But, as I said, the world has changed—or at least *is changing* for most of us. We no longer live in such an oppressive environment. We no longer need to play by the old rules, and rein in our peculiar strengths and idiosyncrasies. We can afford to take risks now we couldn't before. So, yes, I'm hopeful. I think it really ought to be possible to devise placebo treatments for the self, which do indeed induce them to come out from their protective shells — and so to emerge as happier, nicer, cleverer, more creative people than they would ever otherwise have dared to be."
[^sleep]: [Nick Bostrom](!Wikipedia) & [Anders Sandberg](!Wikipedia)'s ["Converging Cognitive Enhancements"](http://www.nickbostrom.com/papers/converging.pdf) (2006):

    > Keeping awake using stimulants prevents the memory consolidation that would have taken place during sleep, and enhanced concentration ability may impair the ability to notice things in peripheral awareness.
[^doogie]: Bostrom/Sandberg 2006:

    > "Genetic memory enhancement has been demonstrated in rats and mice. In normal animals, during maturation expression of the NR2B subunit of the [N-methyl-D-aspartate](!Wikipedia "NMDA receptor") (NMDA) receptor is gradually replaced with expression of the NR2A subunit, something that may be linked to the lower brain plasticity in adult animals. Tsien's group (Tang et al. 1999) modified mice to overexpress the NR2B. The NR2B ['Doogie'](!Wikipedia "Doogie mice") mice demonstrated improved memory performance, both in terms of acquisition and retention. This included unlearning of fear conditioning, which is believed to be due to the learning of a secondary memory (Falls et al. 1992). The modification also made the mice more sensitive to certain forms of pain, suggesting a nontrivial trade-off between two potential enhancement goals (Wei et al. 2001)."

## EOC

In ["The Wisdom of Nature: An Evolutionary Heuristic for Human Enhancement"](http://www.nickbostrom.com/evolution.pdf), [Nick Bostrom](!Wikipedia) puts this principle as:

> If the proposed intervention would result in an enhancement, why have we not already evolved to be that way?

Obviously we humans do intervene all the time, and many of those interventions are worthwhile. Women, for example, are big fans of [birth control](!Wikipedia "Combined oral contraceptive pill"), and if the female reproductive system isn't controlled by evolution, nothing is.

### Loopholes

There may be no free lunches, but might there be some cheap lunches? Yudkowsky's formulation points out several ways to escape the law:

1. interventions may not be *simple*

    So one might find major enhancements through some very complex surgery or prosthetic; perhaps brain implants which expand memory or enable (controlled) [wireheading](!Wikipedia)
2. the simple interventions may not lead to a *major* enhancement

    Nutritional supplements are examples; it makes perfect sense that fixing a chemical deficiency could be a simple matter and enhance fitness - but one would expect minor mental enhancements and this effect would not generalize to very many people. (Similarly, most nootropics do not do very much.)
3. the intervention may be simple, give major enhancements, but result in a *net* loss of fitness

    The famous [Ashkenazi theory of intelligence](!Wikipedia "Ashkenazi intelligence") comes to mind. According to this theory, the Ashkenazi were forced into occupations demanding intelligence, and micro-selected for high IQ. Except the high IQ genes were not previously prevalent among either Jews or gentiles because - like [sickle-cell anemia](!Wikipedia) -s when they became too prevalent, they result in horrible diseases like [Tay-Sachs](!Wikipedia).

Bostrom also offers 3 categories of ways in which interventions can escape his 'EOC':

1. "*Changed tradeoffs*. Evolution 'designed' the system for operation in one type of environment, but now we wish to deploy it in a very different type of environment. It is not surprising, then, that we might be able to modify the system better to meet the demands imposed on it by the new environment."
2. "*Value discordance*. There is a discrepancy between the standards by which evolution measured the quality of her work, and the standards that we wish to apply. Even if evolution had managed to build the finest reproduction-and-survival machine imaginable, we may still have reason to change it because what we value is not primarily to be maximally effective inclusive-fitness optimizers.
3. "*Evolutionary restrictions*. We have access to various tools, materials, and techniques that were unavailable to evolution. Even if our engineering talent is far inferior to evolution's, we may nevertheless be able to achieve certain things that stumped evolution, thanks to these novel aids."

### Examples

Bostrom's criteria are more general, so we'll use them. Birth control is a clear example of satisfying loophole #2, 'value discordance'. Many women do not value having a dozen children while young; they would rather have just 2 at a time of their choosing. Pacemakers are an example of #3: evolution couldn't afford to engineer more reliable hearts, in part for lack of electronic microchips. Many traits related to nutrition fall into the category of #1.^[["Adaptive no more: A potential benefit in prehistoric lean times, genetic variant may increase risk of gestational diabetes today"](http://www.sciencenews.org/view/generic/id/69610/title/Adaptive_no_more), or see the [thrifty gene hypothesis](!Wikipedia).]

How about supplements? Most supplements are just tweaking biochemical processes, and don't obviously fall under 1, 2, or 3. [Melatonin](), for example, may seem particularly questionable as one's body secrets considerable quantities in an intricate cycle (but [see later](#melatonin)).

#### Piracetam

Or in ["Growing up is hard"](http://lesswrong.com/lw/xd/growing_up_is_hard/), [Eliezer Yudkowsky](!Wikipedia) remarks that Bostrom's EOC is:

> "...one reason to be wary of, say, [cholinergic](!Wikipedia) memory enhancers [such as [piracetam](!Wikipedia)]: if they have no downsides, why doesn't the brain produce more [acetylcholine](!Wikipedia) already?  Maybe you're using up a limited memory capacity, or forgetting something else..."

Let's consider the specific case of piracetam. Piracetam is so old and has so many studies on its efficacy (real if not substantial) and safety (utterly) that it screens off a lot of secondary considerations.

- Might piracetam escape the EOC with #3?

    No. Whatever receptors or buttons piracetam pushes could already be pushed by the brain the usual way. There is nothing novel about piracetam in that sense.

- Might piracetam escape the EOC with #2?

    Perhaps. Hard to see how piracetam trades off reproductive fitness for something else, though. It's safe, unlike other substances such as tobacco.

- Might piracetam escape the EOC with #1?

    Probably. Many tradeoffs are different in contemporary First World countries than from the proverbial Stone Age veldt.

A 'cholinergic' operates by encouraging higher levels of the acetylcholine neurotransmitter; acetylcholine is one of the most common neurotransmitters. If serotonin is loosely associated with mood, we might say that acetylcholine is loosely associated with the 'velocity' of thoughts in the brain. If one is using more acetylcholine, one needs to create more acetylcholine (the brain cannot borrow indefinitely like the US federal government). Acetylcholine is made out of the [essential nutrient](!Wikipedia) [choline](!Wikipedia).

An interesting thing about piracetam use is that it doesn't do very much by itself^[See [Wikipedia](!Wikipedia "Piracetam#Side effects") or look at the literature, eg. ["Profound effects of combining choline and piracetam on memory enhancement and cholinergic function in aged rats"](http://www.sciencedirect.com/science/article/pii/0197458081900075) 2003]. It is charitably described as 'subtle'. The standard advice is to take a choline supplement with the piracetam: a gram of [soy lecithin](!Wikipedia), choline bitartate, or choline citrate.

Isn't this interesting? Presumably we are not Irish peasants consuming wretched diets of potato, potato, and more potato, with some mutton on the holidays. We are cognizant of how a good diet & exercise are prerequisites to brain power. Yet, a gram of straight choline still boosts piracetam's effects from subtle or placebo, to noticeable & measurable.

This suggests that perhaps a normal First World diet is choline-deficient. If even well-fed humans must economize on choline & acetylcholine, then surely our ancestors, who were worse off nutritionally, had to economize even more severely. Evolution would frown on squandering acetylcholine on idle thoughts like 'what was that witty saying by Ugh the other day?' That choline might be needed in the next famine! This suggestion is buttressed by one mouse experiment:

> "Administering choline supplementation to pregnant rats improved the performance of their pups, apparently as a result of changes in neural development in turn due to changes in *gene expression* (Meck et al. 1988; Meck and Williams 2003; Mellott et al. 2004). Given the ready availability of choline supplements, such prenatal enhancement, may already (inadvertently) be taking place in human populations. Supplementation of a mother's diet during late and 3 months postpartum with long-chained fatty acids has also been demonstrated to improve cognitive performance in human children (Helland et al. 2003)."^[Emphasis added; Bostrom/Sandberg 2006.]

Past our embryo-hood, we can't tell our bodies that we have available as much choline as it could possibly need, that we value our synapses blazing at every moment more than a better chance of surviving a famine (which effectively no longer exist). So we have to override it, for our own good.

It's worth noting here that there is considerable overlap between #1 and #2. Whether you see piracetam as a conflict in values between evolution's worst-case planning and our desire for greater average or peak performance, or as a shift in optimal expenditure based on a historical drop in bulk quantities of choline, is a matter of preference.

#### Melatonin

How about [melatonin](Melatonin)? It is a clear-cut example of failing #3, but perhaps it passes under #1 like piracetam?

A [shift worker](!Wikipedia) is an obvious case of value discordance: humans are meant to work mostly during the day, with minimal dangerous night-time activity. Shift workers perversely insist on doing the exact opposite, even struggling against the circadian rhythms (to the detriment of [their health](!Wikipedia "Shift work sleep disorder")). Evolution wots not of your 'employment contract', pitiful human!

Regular people have a less extreme version of the shift worker's dilemma. The modern population doesn't rise and set with the sun, for imponderable reasons. (My personal theory is widespread _[akrasia](!Wikipedia)_: darkness overcomes [hyperbolic discounting](!Wikipedia) and forced the ancients to bed, but we have electric lighting and can stay up indefinitely.) This leads to a values mismatch, and a similar solution.

#### Modafinil

[Modafinil]() is another drug that seems suspiciously like a free lunch. The [side-effects](Modafinil#side-effects) are minimal and rare, and the benefit quite unusual and striking: not needing to sleep for a night. The research on general cognitive benefits is mixed but real[^modafinil]. (My own [experience with armodafinil](Nootropics#armodafinil) was that after 41 hours of sleep-deprivation, my [working memory](!Wikipedia) and focus were actually *better* than normal as judged by [dual n-back](DNB FAQ) scores.) Yes, modafinil costs money, but that's not really relevant to our health or to Evolution. Yes, there is, anecdotally, a risk of coming to [tolerate](Modafinil#tolerance) modafinil (although no addiction), but again that doesn't matter to Evolution - there would still be benefits before the tolerance kicked in.

What heuristic might we use?

- Chemically, modafinil does not seem to be so bizarre that evolution could not stumble across it or an equivalent mechanism, so probably we cannot appeal to #3, "evolutionary restrictions".
- Nor is it clear what value discordance might be involved. We could come up with one, though.

    If one theorized that modafinil came with a memory penalty, inasmuch as memory consolidation and the hippocampus seem to intimately involve sleep, then we might have a discordance where we value being able to produce and act more than being able to remember things. This might even be a sensible tradeoff for a modern man: *why not* sacrifice some ability to learn or remember long-term, since you can immediately gain back that capacity and more by suitable use of efficient memory techniques like [spaced repetition]()?
- \#1 seems promising. Like piracetam, there *is* something in short supply that modafinil would use more of: calories! While you are awake, you are burning more calories than while asleep. You are also - in the ancient evolutionary environment - perhaps exposing yourself to additional risks in the dark night. (This would be the [preservation & protection theory of sleep](!Wikipedia "Sleep#Preservation").)

    Resource usage is a real concern for the human brain: it uses [<20%](http://www.scientificamerican.com/article.cfm?id=why-does-the-brain-need-s) of energy; [87%](http://discovermagazine.com/2011/jul-aug/06-body-fit-for-freaky-big-brain#) in infants. One [blogger](http://www.replicatedtypo.com/science/what-makes-humans-unique-i-the-evolution-of-the-human-brain/1372/) says:

    > "Although it only accounts for 2% of an adult's body weight, it accounts for 20-25% of an adult's resting oxygen and energy intake ([Attwell & Laughlin 2001](http://www.neuroscienceschool.ku.dk/cbfm_literature/attwell%20laughlin.pdf): 1143). In early life, the brain even makes up for up 60-70% of the body’s total energy requirements. A chimpanzee's brain, in comparison, only consumes about 8-9% of its resting metabolism ([Aiello & Wells 2002](http://people.biology.ufl.edu/sphelps/documents/evobrain/aeillo_wheeler_95.pdf): 330). The human brain's energy demands are about 8 to 10 times higher than those of skeletal muscles ([Dunbar & Shultz 2007](http://herd.typepad.com/herd_the_hidden_truth_abo/files/Dunbar_etal_2007.pdf): 1344), and, in terms of energy consumption, it is equal to the rate of energy consumed by leg muscles of a marathon runner when running (Attwell & Laughlin 2001: 1143). All in all, its consumption rate is only topped by the energy intake of the heart (Dunbar & Shultz 2007: 1344)."

    There are additional disadvantages to increased intelligence - larger heads would drive maternal & infant mortality rates even higher than they are. And it's worth noting that while the human brain is [disproportionately huge](!Wikipedia "Brain-to-body mass ratio#Comparisons between groups"), yet the human [cerebral cortex](!Wikipedia) is *not* any bigger than one would predict be extrapolating from gibbon or ape cortex volumes, despite the human lineage splitting off millions of years ago.[^cortex] There are other ways in which humans seem to have hit intelligence limits - why did our ancestors' brains grow in volume for millions of years^[See the chart on page 3 of ["The pattern of evolution in Pleistocene human brain size"](http://www-personal.umich.edu/~wolpoff/Papers/Brain%20Size.pdf); note also how high some of the recent skull volumes are - ~1800 cc - compared to modern [cranial capacity](!Wikipedia) with an average closer to 1500 cc (although apparently modern extremes can still reach 1800-1900 cc).], only to come to a halt with the Neanderthals & Cro-Magnons and actually start shrinking^[["Evolution of the human brain: is bigger better?"](http://www.ncbi.nlm.nih.gov/pubmed/9750968): "Since the Late Pleistocene (approximately 30,000 years ago), human brain size decreased by approximately 10%"] to the modern volume, and why did old age only start increasing 50,000 years ago or later[^oldage], well after humans began developing technology like controlled fire (>=400,000 years ago^[See ["Fire in the Earth System"](https://www.sciencemag.org/content/324/5926/481), _Science_]); or why are primate guts (also resource-expensive) [inversely correlated](http://people.biology.ufl.edu/sphelps/documents/evobrain/aeillo_wheeler_95.pdf) with brain size or muscles starved of sugars and brains favored[^muscles]; or why do the [Ashkenazi](!Wikipedia "Ashkenazi intelligence") seem to pay for their intelligence with endemic genetic disorders; or why does evolution permit human brains to shrink dramatically with age, as much as 15% of volume, besides the huge [performance losses](DNB FAQ#aging), while the brains of our closest relative-species (the chimpanzees), do not shrink at all?[^chimps] The obvious answer is that [diminishing returns](!Wikipedia) have kicked in for intelligence in primates and humans in particular[^sciam][^hydrocephalic]. (Indeed, it's apparently been argued that not only are humans not much smarter than primates^[eg. chimpanzees outperform humans on the simple working memory task [Monkey Ladder](http://www.cambridgebrainsciences.com/assets/default/files/pdf/Inoue2007.pdf). Another fun statistic is that besides obviously being [stronger, faster](http://www.slate.com/articles/health_and_science/science/2009/02/how_strong_is_a_chimpanzee.single.html), and more dangerous than humans, chimpanzees have better immune systems inasmuch as they [don't overreact](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3085894/) - over-reacting being a major cause of common issues like arthritis or asthma.], but there is little overall intelligence differences in vertebrates[^lion]. Humans lose embarrassingly on even pure tests of statistical reasoning; we are outperformed on the [Monty Hall problem](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3086893/pdf/nihms288435.pdf) by *pigeons*!) The last few millennia aside, humans have not done well and has apparently [verged on extinction](!Wikipedia "Population bottleneck#Humans") before, and the [demographic transition](!Wikipedia)[^transition] and anthropogenic [existential risk](!Wikipedia)s suggest that our current success may be short-lived (not that [agriculture & civilization](http://www.ditext.com/diamond/mistake.html) were great in the first place). <!-- ways in which intelligence is harmful: http://www.weidai.com/smart-losers.txt -->

    Modafinil or modafinil-like traits might be selected against due to increased calorie expenditure, [decreased calorie consumption](!Wikipedia "Modafinil#Weight loss"), or risks of night-time activity. Either explanation fails in a modern environment; modern societies have murder and assault rates orders of magnitude lower than that seen among aborigines^[See [Steve Pinker](!Wikipedia)'s ["A History of Violence"](http://www.edge.org/3rd_culture/pinker07/pinker07_index.html) and the better-referenced ["A History of Violence": Edge Master Class 2011](http://edge.org/conversation/mc2011-history-violence-pinker), culminating in his 2011 book, _The Better Angels of Our Nature_.], and calories are so abundant that they have begun *reducing* fitness (we call this being poisoned by too many calories the [obesity epidemic](!Wikipedia)).

Is that last a convincing defense of modafinil against the EOC or Algernon's principle? It seems reasonable to me, if not as strong a defense as I would like.

[^oldage]: The data is uncertain, but there seems to be a significant increase in ratio of old skeletons found over time; Caspari & Lee 2004 (["Older age becomes common late in human evolution"](http://www.pnas.org/content/101/30/10895.full.pdf+html)), pg 2, find the 'older to younger adults ratio' for various humanoid groups to be:

    1. [Australopithecines](!Wikipedia): 0.12
    2. Early _Homo_: 0.25
    3. Neandertals: 0.39
    4. Early [Upper Paleolithic](!Wikipedia): 2.08
    5. All: 0.28

    This could have many explanations (perhaps a slow accretion of technology/culture allowed older people to survive with no connection to human biology or evolution), but in this context, I can't help but wonder - could old age be increasing because intelligence is *so* expensive that old age is the only way for the genes to recoup their investments? Or could it be that increases in human intelligence used to pay off within a normal lifespan because the humans learned *faster*, but now they have reached a limit on their intelligence, how *fast* they learn, and so to be more effective, the slow learners have to learn for *longer*?
[^cortex]: pg 2, ["The likelihood of cognitive enhancement"](http://www.ncbi.nlm.nih.gov/pubmed/21215768) ([PDF](/docs/2011-lynch.pdf)), Lynch et al 2011:

    > "Anatomists often resort to allometry when dealing with questions of selective pressures on brain regions. Applied to brain proportions, this involves collecting measurements for the region of interest—e.g., frontal cortex—for a series of animals within a given taxonomic group and then relating it to the volume or weight of the brains of those animals. This can establish with a relatively small degree of error whether a brain component in a particular species is larger than would be predicted from that species' brain size. While there is not a great deal of evidence, studies of this type point to the conclusion that cortical subdivisions in humans, including association regions, are about as large as expected for an anthropoid primate with a 1350 cm3 brain. The volume of area 10 of human frontal cortex, for example, fits on the regression line (area 10 vs. whole brain) calculated from published data (Semendeferi et al., 2001) for a series composed of gibbons, apes and humans (Lynch and Granger, 2008). Given that this region is widely assumed to play a central role in executive functions and working memory, these observations do not encourage the idea that selective pressures for cognition have differentially shaped the proportions of human cortex. Importantly, this does not mean that those proportions are in any sense typical. The allometric equations involve different exponents for different regions, meaning that absolute proportions (e.g., primary sensory cortex vs. association cortex) change as brains grow larger. The balance of parts in the cortex of the enormous human brain is dramatically different than found in the much smaller monkey brain: area 10, for instance, occupies a much greater percentage of the cortex in man. But these effects seem to reflect expansion according to rules embedded in a conserved brain plan rather than selection for the specific pattern found in humans (Finlay et al., 2001)."
[^modafinil]: Lynch et al 2011

    > "There is a large and often conflicting literature on the effects of modafinil on components of cognition. Some studies obtained a clear improvement in sustained attention in healthy human subjects (Randall et al., 2005) but others failed to find such effects (Turner et al., 2003). Similar discrepancies occur in the literature on animals (Waters et al., 2005). A recent, multi-factorial analysis provided  convincing evidence that moderate doses of modafinil improve attention in healthy middle-aged rats without affecting motivation or locomotor activity (Morgan et al., 2007). Importantly, these effects became evident only as attentional demands were increased. In all, it seems reasonable at this point to conclude that modafinil's effects on basic psychological state variables—wakefulness—can translate into selective improvements in attention.
    >
    > There is also a sizable literature suggesting that the above conclusion can be extended to memory encoding. An intriguing aspect of these studies in rodents (Beracochea et al., 2002) and humans (Turner et al., 2003; Baranski et al., 2004; Muller et al., 2004; Randall et al., 2005) is that they generally point to a drug influence on working memory as opposed to the encoding of long-term memory for specific information (Minzenberg and Carter, 2008). (A similar argument was made earlier for Ritalin.) For example, the above noted work on middle-aged rats found no evidence for accelerated acquisition of a visual discrimination problem, with minimal demands on working memory, despite clear improvements in attention. There  are, however, studies showing that modafinil accelerates the acquisition of simple rules (‘win-stay') (Beracochea et al., 2003), a spatial learning protocol (Shuman et al., 2009), and a non-match to position problem (Ward et al., 2004) in rodents. It is tempting to speculate that we are here seeing hierarchical effects of modafinil such that enhanced wakefulness produces greater attention that in turn improves both working memory and simple rule learning.
    >
    > But does the above sequence in fact improve the integrative psychological processes that constitute cognition? By far the greater part of the human studies with modafinil involves subjects with impairments to performance (sleep deprivation) or psychiatric dis- orders. None of the animal studies used recently developed tests (see below) that are explicitly intended to assess variables such as recall vs. recognition or ‘top-down' forcing of attention. This leaves a small set of experiments involving performance by healthy human subjects on relatively simple learning/perceptual problems. A retrospective analysis of several studies led to the conclusion that modafinil does not produce a ‘global' enhancement of cognition (Randall et al., 2005)."
[^chimps]: ["Aging of the cerebral cortex differs between humans and chimpanzees"](http://www.pnas.org/content/early/2011/07/20/1016709108), PNAS 2011:

    > "...overt volumetric decline of particular brain structures, such as the hippocampus and frontal lobe, has only been observed in humans....In contrast to humans, who showed a decrease in the volume of all brain structures over the lifespan [on fMRI], chimpanzees did not display significant age-related changes. Using an iterative age-range reduction procedure, we found that the significant aging effects in humans were because of the leverage of individuals that were older than the maximum longevity of chimpanzees. Thus, we conclude that the increased magnitude of brain structure shrinkage in human aging is evolutionarily novel and the result of an extended lifespan."
[^muscles]: ["The Brain A Body Fit for a Freaky-Big Brain"](http://discovermagazine.com/2011/jul-aug/06-body-fit-for-freaky-big-brain/article_view?b_start:int=1&-C=), Carl Zimmer:

    > "...Wray and his colleagues compared SLC2A1 in humans and other animals. They discovered that our ancestors acquired an unusually high number of mutations in the gene. The best explanation for that accumulation of mutations is that SLC2A1 experienced natural selection in our own lineage, and the new mutations boosted our reproductive success. Intriguingly, the Duke team discovered that the mutations didn't alter the shape of the glucose transporters. Rather, they changed stretches of DNA that toggled the SLC2A1 gene on and off.
    >
    > Wray guessed that these mutations changed the total number of glucose transporters built in the human brain. To test his theory, he looked at slices of human brain tissue. In order to make glucose transporters, the cells must first make copies of the SLC2A1 gene to serve as a template. Wray discovered that in human brains there were 2.5 to 3 times as many copies of SLC2A1 as there were in chimpanzee brains, suggesting the presence of more glucose transporters as well.
    >
    > Then he looked at glucose transporters that deliver the sugar to muscles. The gene for these muscle transporters, called SLC2A4, also underwent natural selection in humans, but in the opposite direction. Our muscles contain fewer glucose transporters than in chimps' muscles. Wray's results support the notion that our ancestors evolved extra molecular pumps to funnel sugar into the brain, while starving muscles by giving them fewer transporters."
[^sciam]: To extensively quote the June 2011 [_Scientific American_ cover story](http://www.overcomingbias.com/2011/07/whence-better-brains.html):

    > ""I think it is very likely that there is a law of diminishing returns" to increasing intelligence indefinitely by adding new brain cells.... Size carries burdens with it, the most obvious one being added energy consumption. In humans, the brain is already the hungriest part of our body: at 2 percent of our body weight, this greedy little tapeworm of an organ wolfs down 20 percent of the calories that we expend at rest. In newborns, it's an astounding 65 percent....
    >
    > For decades this dividing of the brain into more work cubicles was viewed as a hallmark of intelligence. But it may also reflect a more mundane truth...: specialization compensates for the connectivity problem that arises as brains get bigger. As you go from a mouse brain to a cow brain with 100 times as many neurons, it is impossible for neurons to expand quickly enough to stay just as well connected. Brains solve this problem by segregating like-functioned neurons into highly interconnected modules, with far fewer long-distance connections between modules. The specialization between right and left hemispheres solves a similar problem; it reduces the amount of information that must flow between the hemispheres, which minimizes the number of long, interhemispheric axons that the brain needs to maintain. "All of these seemingly complex things about bigger brains are just the backbends that the brain has to do to satisfy the connectivity problem" as it gets larger... "It doesn't tell us that the brain is smarter."...
    >
    > Neurons do get larger as brain size increases, but not quite quickly enough to stay equally well connected. And axons do get thicker as brains expand, but not quickly enough to make up for the longer conduction delays....
    >
    > In fact, neuroscientists have recently seen a similar pattern in variations within humans: people with the quickest lines of communication between their brain areas also seem to be the brightest. One study... used functional magnetic resonance imaging to measure how directly different brain areas talk to one another—that is, whether they talk via a large or a small number of intermediary areas.... Shorter paths between brain areas correlated with higher IQ.... [Others] compared working memory (the ability to hold several numbers in one's memory at once) among 29 healthy people.... People with the most direct communication and the fastest neural chatter had the best working memory.
    >
    > It is a momentous insight. We know that as brains get larger, they save space and energy by limiting the number of direct connections between regions. The large human brain has relatively few of these long-distance connections. But... these rare, nonstop connections have a disproportionate influence on smarts: brains that scrimp on resources by cutting just a few of them do noticeably worse....
    >
    > There is another reason to doubt that a major evolutionary leap could lead to smarter brains. Biology may have had a wide range of options when neurons first evolved, but 600 million years later a peculiar thing has happened. The brains of the honeybee, the octopus, the crow and intelligent mammals, Roth points out, look nothing alike at first glance. But if you look at the circuits that underlie tasks such as vision, smell, navigation and episodic memory of event sequences, "very astonishingly they all have absolutely the same basic arrangement." Such evolutionary convergence usually suggests that a certain anatomical or physiological solution has reached maturity so that there may be little room left for improvement....
    >
    > So have humans reached the physical limits of how complex our brain can be, given the building blocks that are available to us? Laughlin doubts that there is any hard limit on brain function the way there is one on the speed of light. "It's more likely you just have a law of diminishing returns," he says. "It becomes less and less worthwhile the more you invest in it." Our brain can pack in only so many neurons; our neurons can establish only so many connections among themselves; and those connections can carry only so many electrical impulses per second. Moreover, if our body and brain got much bigger, there would be costs in terms of energy consumption, dissipation of heat and the sheer time it takes for neural impulses to travel from one part of the brain to another."

    Counter-evidence would be observations that indicate evolution trying to compensate for limits in one system by investing even more into another system; for example, it has been observed that childbirth in humans is extremely risky and dangerous compared to other primates because the infant head is so enormous compared to the birth canal. If intelligence weren't valuable, one would expect the head size to remain constant or decrease, and one certainly would not expect the over-sized human brain to grow even faster after child birth; yet the human [prefrontal cortex](http://www.sciencedirect.com/science/article/pii/S0960982211007883) grows much faster in infancy than the chimpanzee prefrontal cortex does.
[^lion]: ["If a Lion Could Talk: Animal Intelligence and the Evolution of Consciousness"](https://www.nytimes.com/books/first/b/budiansky-lion.html), Stephen Budiansky:

    > "...Giving a blind person a written IQ test is obviously not a very mean meaningful evaluation of his mental abilities. Yet that is exactly what many cross-species intelligence tests have done. Monkeys, for example, were found not only to learn visual discrimination tasks but to improve over a series of such tasks -- they formed a learning set, a general concept of the problem that betokened a higher cognitive process than a simple association. Rats given the same tasks showed difficulty in mastering the problems and no ability to form a learning set. The obvious conclusion was that monkeys are smarter than rats, a conclusion that was comfortably accepted, as it fit well with our preexisting prejudices about the distribution of general intelligence in nature. But when the rat experiments were repeated, only this time the rats were given the task of discriminating different smells, they learned quickly and showed rapid improvement on subsequent problems, just as the monkeys did.
    >
    > The problem of motivation is another major confounding variable. Sometimes we may think we are testing an animal's brain when we are only testing its stomach. For example, in a series of studies goldfish never learned to improve their performance when challenged with "reversal" tasks. These are experiments in which an animal is trained to pick one of two alternative stimuli (a black panel versus a white panel, say) in order to obtain a food reward; the correct answer is then switched and the subject has to relearn which one to pick. Rats quickly learned to switch their response when the previously rewarded answer no longer worked. Fish didn't. This certainly fit comfortably with everyone's sense that fish are dumber than rats. But when the experiment was repeated with a different food reward (a paste squirted into the tank right where the fish made its correct choice, as opposed to pellets dropped into the back of the tank), lo and behold the goldfish suddenly did start improving on reversal tasks. Other seemingly fundamental learning differences between fish and rodents likewise vanished when the experiments were redesigned to take into account differences in motivation.
    >
    > Equalizing motivation is an almost insoluble problem for designers of experiments. Are three goldfish pellets the equivalent of one banana or fifteen bird seeds? How could we even know? We would somehow have to enter into the internal being of different animals to know for sure, and if we could do that we would not need to be devising roundabout experiments to probe their mental processes in the first place.
    >
    > When we do control for all of the confounding variables that we possibly can, the striking thing about the "pure" cognitive differences that remain is how the similarities in performance between different animals given similar problems vastly outweigh the differences. To be sure, there seems to be little doubt that chimpanzees can learn new associations with a single reinforced trial, and that that is genuinely faster than other mammals or pigeons do it. Monkeys and apes also learn lists faster than pigeons do. Apes and monkeys seem to have a faster and more accurate grasp of numerosity judgments than birds do. The ability to manipulate spatial information appears to be greater in apes than in monkeys.
    >
    > But again and again experiments have shown that many abilities thought the sole province of "higher" primates can be taught, with patience, to pigeons or other animals. Supposedly superior rhesus monkeys did better than the less advanced cebus monkeys in a visual learning-set problem using colored objects. Then it turned out that the cebus monkeys did better than the rhesus monkeys when gray objects were used. Rats were believed to have superior abilities to pigeons in remembering locations in a radial maze. But after relatively small changes in the procedure and the apparatus, pigeons did just as well.
    >
    > If such experiments had shown, say, that monkeys can learn lists of forty-five items but pigeons can only learn two, we would probably be convinced that there are some absolute differences in mental machinery between the two species. But the absolute differences are far narrower. Pigeons appear to differ from baboons and people in the way they go about solving problems that involve matching up two images that have been rotated one from the other, but they still get the right answers. They essentially do just as well as monkeys in categorizing slides of birds or fish or other things. Euan Macphail's review of the literature led him to conclude that when it comes to the things that can be honestly called general intelligence, no convincing differences, either qualitative or quantitative, have yet been demonstrated between vertebrate species. While few cognitive researchers would go quite so far -- and in deed we will encounter a number of examples of differences in mental abilities between species that are hard to explain as anything but a fundamental difference in cognitive function -- it is striking how small those differences are, far smaller than "common sense" generally has it. Macphail has suggested that the "no-difference" stance should be taken as a "null hypothesis" in all studies of comparative intelligence; that is, it is an alternative that always has to be considered and ought to be assumed to be the case unless proven otherwise."
[^transition]: ["The pursuit of happiness (with or without kids)"](http://news.bbc.co.uk/2/hi/uk_news/magazine/3270029.stm), _BBC News Online Magazine_ 2003:

    > Again, the figures do not bear it out. While the birth rate in the UK is the lowest since records began in 1924, our level of contentment has remained fairly steady. Two of the foremost thinkers on well-being, Richard Layard and Andrew Oswald, agree that children have a statistically insignificant impact on our happiness....In 2001, almost 90% of British people reported they were very or fairly satisfied with life. According to this new study, those without children are, by and large, every bit as content as those with...For mothers in particular, parenthood brings a new sort of pleasure, the result of spending time with their children, seeing them develop and providing a different take on life. Yet this comes at a cost, both financial and emotional, according to the report, which spoke to 1,500 adults, parents and non-parents, between the ages of 20 and 40. "Full-time working mothers are lower paid relative to women without children," says Kate Stanley, who carried out the survey for the Institute for Public Policy Research. Most women also tend to take on the lion's share of domestic and child-care duties, according to the survey. And since income and independence have a bearing on happiness, what motherhood giveth with one hand, it taketh away with the other. The trade-off is less acute for men, but according to the survey, they are less ecstatic about children anyway. While two-thirds of mothers say their children make them most happy, just over 40% of fathers agree...On the other side, those without children recognise they are freer to pursue their own interests and enjoyment than their tied-up, family-focused friends."

    This is also true in the United States, according to Abma, J.C. & Martinez, G.M. (2006). "Childlessness among older women in the United States: trends and profiles". _Journal of Marriage and Family_ 68, 1045-1056; see also ["Does Having Children Create Happiness?"](http://www.estebancalvo.com/files/teaching_files/Children_v2.pdf) (answer: no).
[^hydrocephalic]: One peculiar example of how human brains may represent diminishing returns with a vengeance is how little damage losing most of the brain can cause - the loss of neurons and brain volume involved in [hydrocephalus](!Wikipedia) can be staggering, yet result only in mental impairment (as opposed to *death*) or even result in individuals who are above-normal in IQ & 'bright'; neuroscientist Bradley Voytek covers examples in ["Why We Don't Need A Brain"](http://blog.ketyov.com/2011/03/why-we-dont-need-brain.html).

#### Heroin

How about opiates? Morphine and other painkillers can easily be justified as evolution not knowing when a knife cut is by a murderous enemy and when it's by a kindly surgeon (which didn't exist way back when), and choosing to make us err on the side of always feeling pain. But recreational drug abuse?

- \#1 doesn't seem too plausible - what about modern society would favor opiate consumption outside of medicinal use? If one wishes to deaden the despair and ennui of living in a degenerate atheistic material culture, we have beer for that.^["Ale, man, ale's the stuff to drink / For fellows whom it hurts to think."]
- \#3 doesn't work either; opioids have been around for ages and work via the standard brain machinery.
- \#2 might work here as well, but this dumps us straight into the debate about the [War on Drugs](!Wikipedia) and what harm drug use does to the user & society.

But even this analysis is helpful: we now know on what basis to oppose drug use, and most importantly, what *kind* of evidence which we should look for to support or falsify our belief about heroin.

# External links

- [LessWrong draft comments](http://lesswrong.com/lw/26x/open_thread_may_2010/1yqp?c=1)
