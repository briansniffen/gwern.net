---
description: Efficient memorization (using Mnemosyne) & what it's good for.
...

> "Most people find the concept of programming obvious, but the doing impossible."^[Alan J. Perlis, ["Epigrams in Programming"](http://www.cs.yale.edu/quotes.html)]

One of the most fruitful areas of computing is making up for human frailties. They do arithmetic perfectly because we can't^["One does not learn computing by using a hand calculator, but one can forget arithmetic." Perlis, _ibid._]. They remember terabytes because we'd forget. They make the best calendars, because they always check what there is to do today.

We use any number of such [neuroprosthetic](!Wikipedia)s, but there are always more to be discovered. They're worth looking for because they are so valuable: a shovel is much more effective than your hand, but a [power shovel](!Wikipedia) is orders of magnitude better than both - even if it requires training and expertise to use.

# Spacing effect

My current favorite prosthesis is the class of software that exploits the [spacing effect](!Wikipedia), a centuries-old observation in cognitive psychology, to achieve results in studying or memorization much better than conventional student techniques[^efficiency].

The spacing effect essentially says that if you have a question ("What is the fifth letter in this random sequence you learned?"), and you can only study it, say, 5 times, then your memory of the answer ('e') will be strongest if you spread your 5 tries out over a long period of time - days, weeks, and months. One of the worst things you can do is blow your 5 tries within a day or two. You can think of the 'forgetting curve' as being like a chart of radioactive half-lives: each review bumps your memory up in strength 50% of the chart, say, but review doesn't do very much in the early days because the memory simply hasn't decayed very much!^[For a graphical representation of this sawtooth effect, see [page 2](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak?currentPage=2) of Wolf 2008.] (*Why* does the spacing effect work? That's an open question.)

Even better, it's known that [active recall](!Wikipedia) is a far superior method of learning than simply passively being exposed to information.[^mapping]

A graphic might help; imagine here one can afford to review a given piece of information a few times (one is a busy person). By looking at the odds we can remember the item, we can see that cramming wins in the short term, but unexercised memories decay so fast that after not too long spacing is much superior[^img]:

![Massed versus spaced](images/spaced-repetition-forgetting-curves.png)

## If you're so good...

Of course, the latter strategy (cramming) is precisely what students do. They cram the night before the test, and a month later can't remember anything. So why do people do it? (I'm not innocent myself.)

Because it does work, sort of. Cramming is a trade-off: you trade a strong memory now for no memory later. And tests are usually of all the new material, with occasional old questions, so this strategy pays off! That's the damnable thing about it - its memory longevity & quality are, in sum, less than that of spaced repetition, but cramming delivers its goods *now*. So cramming is a rational, if short-sighted, response. (But as one might expect, if the testing is continuous and incremental, then the learning tends to also be long-lived[^conway]; I do not know if this is because that kind of testing is a disguised accidental spaced repetition system, or the students/subjects simply studying/acting differently in response to small-stakes exams.)

[^conway]: ["Examining the examiners: Why are we so bad at assessing students?"](http://www.commonsenseatheism.com/wp-content/uploads/2011/02/Newstead-Examining-the-examiners.pdf), Stephen Newstead:

    > "[Conway, Cohen and Stanhope (1992)](http://www.sciencedirect.com/science/article/pii/S0096344502002953) looked at long term memory for the information presented on a psychology course. They found that some types of information, especially that relating to research methods, were remembered better than others. But in a follow up analysis, they found that the type of assessment used had an effect on memory. In essence, material assessed by continuous assessment was more likely to be remembered than information assessed by exams."

This short-term perspective is not a good thing in the long term, of course. Knowledge builds on knowledge; one is not learning independent bits of trivia. [Richard Hamming](!Wikipedia) writes in ["You and Your Research"](http://www.cs.virginia.edu/~robins/YouAndYourResearch.html):

> "You observe that most great scientists have tremendous drive. I worked for ten years with John Tukey at Bell Labs. He had tremendous drive. One day about three or four years after I joined, I discovered that John Tukey was slightly younger than I was. John was a genius and I clearly was not. Well I went storming into Bode's office and said, "How can anybody my age know as much as John Tukey does?" He leaned back in his chair, put his hands behind his head, grinned slightly, and said, "You would be surprised Hamming, how much you would know if you worked as hard as he did that many years." I simply slunk out of the office!
>
> What Bode was saying was this: "Knowledge and productivity are like [compound interest](!Wikipedia)." Given two people of approximately the same ability and one person who works ten percent more than the other, the latter will more than twice outproduce the former. The more you know, the more you learn; the more you learn, the more you can do; the more you can do, the more the opportunity - it is very much like compound interest. I don't want to give you a rate, but it is a very high rate. Given two people with exactly the same ability, the one person who manages day in and day out to get in one more hour of thinking will be tremendously more productive over a lifetime. I took Bode's remark to heart; I spent a good deal more of my time for some years trying to work a bit harder and I found, in fact, I could get more work done."

Knowledge needs to accumulate, and flashcards with spaced repetition can aid in just that accumulation, fostering steady review even as the number of cards and intellectual prerequisites mounts into the [thousands](#the-workload).

This long term focus may explain why explicit spaced repetition an uncommon studying technique: the pay-off is long-term and unobvious. It doesn't help that it's pretty difficult to figure out *when* one should review - the optimal point is when you're just about to forget about it, but that's the kicker: if you're just about to forget about it, how are you supposed to remember to review it? You only remember to review what you remember, and what you already remember isn't what you need to review![^wired1]

The paradox is resolved by letting a computer handle all the calculations. We can thank Ebbinghaus for investigating in such tedious detail than we can, in fact, program a computer to calculate both the forgetting curve and optimal set of reviews^["Make no mistake about it: Computers process numbers - not symbols. We measure our understanding (and control) by the extent to which we can arithmetize an activity." Perlis, _ibid._]. This is the insight behind [spaced repetition](!Wikipedia) software: ask the same question over and over, but over increasing spans of time. You start with asking it once every few days, and soon the human remembers it reasonably well. Then you expand intervals out to weeks, then months, and then years. Once the memory is formed and dispatched to long-term memory, it needs but occasional exercise to remain hale and hearty^[this exponential expansion is how a SR program can handle continual input of cards: obviously if cards were scheduled at fixed intervals, like every other day, review would soon become quite impossible - I have >8000 items in Mnemosyne, but I don't have time to review 4500 questions a day!] - I remember well the large dinosaurs made of cardboard for my 4^th^ or 5^th^ birthday, or the tunnel made out of boxes, even though I recollect them once or twice a year at most.

## Literature review

But don't take my word for it - _Nullius in verba_! We can look at the science. Of course, if you do take my word for it, you probably just want to read about how to use it and all the nifty things you can do, so I suggest you [skip all the way down](#using-it) to that section. Everyone else, we start at the beginning:

### Background: testing works!

> "If you read a piece of text through twenty times, you will not learn it by heart so easily as if you read it ten times while attempting to recite from time to time and consulting the text when your memory fails."^[_[The New Organon](!Wikipedia)_, [Francis Bacon](!Wikipedia)]

The [testing effect](!Wikipedia) is the well-established psychological effect that the mere act of testing someone's memory will strengthen the memory, regardless of whether there is feedback. Since [spaced repetition](!Wikipedia) is just testing on particular days, we ought to establish that testing works better than regular review or study, and that it works outside of memorizing random dates in history. To cover a few studies:

1.  Allen, G.A., Mahler, W.A., & Estes, W.K. (1969). ["Effects of recall tests on long-term retention of paired associates"](http://www.mendeley.com/research/effects-of-recall-tests-on-longterm-retention-of-paired-associate/). _Journal of Verbal Learning and Verbal Behavior_, 8, 463–470

    1 test results in memories as strong a day later as studying 5 times; intervals improve retention compared to massed presentation.

2. Karpicke & Roediger (2003). ["The Critical Importance of Retrieval for Learning"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Karpicke-The-critical-importance-of-retrieval-for-learning.pdf)

    In learning Swahili vocabulary, students were given varying routines of testing or studying or testing and studying; this resulted in similar scores during the learning phase. Students were asked to predict what percentage they'd remember (average: 50% over all groups). One week later, the students who tested remembered ~80% of the vocabulary versus ~35% for non-testing students. Some students were tested or studied more than others; diminishing returns set in very quickly once the memory had formed the first day. Students reported rarely testing themselves and not testing already learned items.

    Lesson: again, testing improves memory compared to studying. Also, no student knows this.

3. Roediger & Karpicke (2006a). ["Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Roediger-Test-Enhanced-Learning.pdf)

    Students were tested (with no feedback) on reading comprehension of a passage over 5 minutes, 2 days, and 1 week. Studying beat testing over 5 minutes, but nowhere else; students believed studying superior to testing over all intervals. At 1 week, testing scores were ~60% versus ~40%.

    Lesson: testing improves memory compared to studying. Everyone (teachers & students) 'knows' the opposite.
4. Karpicke & Roediger (2006a). ["Expanding retrieval promotes short-term retention, but equal interval retrieval enhances long-term retention"](http://learninglab.psych.purdue.edu/downloads/2007_Karpicke_Roediger_JEPLMC.pdf)

    General scientific prose comprehension; from Roediger & Karpicke 2006b: "After 2 days, initial testing produced better retention than restudying (68% vs. 54%), and an advantage of testing over restudying was also observed after 1 week (56% vs. 42%)."
5. Roediger & Karpicke (2006b). ["The Power of Testing Memory: Basic Research and Implications for Educational Practice"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Roediger-The-power-of-testing-memory.pdf)

    Literature review; 7 studies before 1941 demonstrating testing improves retention, and 6 afterwards.
6. Agarwal et al. (2008) ["Examining the Testing Effect with Open- and Closed-Book Tests"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Agarwal-Examining-the-Testing-Effect.pdf)

    As with #2, the purer forms of testing (in this case, open-book versus closed-book testing) did better over the long run, and students were deluded about what worked best.
7. Bangert-Drowns, Kulik, and Kulik (1991). ["Effects of frequent classroom testing"](http://www.jstor.org/pss/27540459)

    Meta-analysis of 35 studies (1929-1989) varying tests during school semesters. 29 found benefits; 5 found negatives; 1 null result. Meta-study found large benefits to testing even once, then diminishing returns.

#### Subjects

The above studies often used pairs of words or words themselves. How well does the testing effect generalize?

Materials which benefited from testing:

- foreign vocabulary (eg. Karpicke & Roediger 2003)
- [GRE](!Wikipedia) materials, prose passages on general scientific topics (Karpicke & Roediger, 2006a; Pashler et al., 2003)
- trivia ([McDaniel & Fisher](http://www.mendeley.com/research/tests-and-test-feedback-as-learning-sources/), 1991)
- elementary & middle school lessons with subjects such as biographical material ([Gates 1917](http://www.archive.org/details/recitationasafa00gategoog); [Spitzer 1939](http://psycnet.apa.org/journals/edu/30/9/641/)[^spitzer], respectively)
- Agarwal et al (2006): short-answer tests superior on textbook passages
- history textbooks; retention better with initial short-answer test rather than multiple choice ([Nungester and Duchastel 1982](http://psycnet.apa.org/journals/edu/74/1/18.pdf))
- [LaPorte & Voss (1975)](http://www.sciencedirect.com/science/article/pii/S0022066307658012) also found better retention compared to multiple-choice or recognition problems
- 6 months after testing, testing beat studying in retention of a history passage [Duchastel & Nungester, 1981](http://psycnet.apa.org/psycinfo/1982-13030-001)
- [Duchastel (1981)](http://www.sciencedirect.com/science/article/pii/0361476X81900023): free recall decisively beat short-answer & multiple choice for reading comprehension of a history passage
- [Glover (1989)](http://www.sciencedirect.com/science/article/pii/S0022066302007869): free recall self-test beat recognition or [Cloze deletions](!Wikipedia); subject matter was the labels for parts of flowers
- [Kang, McDermott, and Roediger (2007)](http://memory.wustl.edu/Pubs/2007_Kang.pdf): prose passages; initial short answer testing produced superior results 3 days later on both multiple choice and short answer tests
- [Leeming (2002)](http://www.eric.ed.gov/ERICWebPortal/recordDetail?accno=EJ761434): tests in 2 psychology courses, introductory & memory/learning; "80% vs. 74% for the introductory psychology course and 89% vs. 80% for the learning and memory course"

[^spitzer]: From Balota, describing Spitzer, H. F. (1939); "Studies in retention"; _Journal of Educational Psychology_, 30, 641–657:

    > "Spitzer (1939) incorporated a form of expanded retrieval in a study designed to assess the ability of sixth graders to learn science facts. Impressively, Spitzer tested over 3600 students in Iowa—the entire sixth-grade population of 91 elementary schools at the time. The students read two articles, one on peanuts and the other on bamboo, and were given a 25-item multiple choice test to assess their knowledge (such as “To which family of plants does bamboo belong?”). Spitzer tested a total of nine groups, manipulating both the timing of the test (administered immediately or after various delays) and the number of identical tests students received (one to three). Spitzer did not incorporate massed or equal interval retrieval conditions, but he had at least two groups that were tested on an expanding schedule of retrieval, in which the intervals between tests were separated by the passage of time (in days) rather than by intervening to-be-learned information. For example, in one of the groups, the first test was given immediately, the second test was given seven days after the first test, and the third test was given 63 days after the second test. Thus, in essence, this group was tested on a 0-7-63 day expanding retrieval schedule. Spitzer compared performance of the expanded retrieval group to a group given a single test 63 days after reading the original article. On the first (immediate) test, the expanded retrieval group correctly answered 53% of the questions. After 63 days and two previous tests, their score was still an impressive 43%. The single test group correctly answered only 25% of the original items after 63 days, giving the expanded retrieval group an 18% retention advantage. This is quite impressive, given that this large benefit remained after a 63-day retention interval. Similar beneficial effects were found in a group tested on a 0-1-21 day expanded retrieval schedule compared to a group given a single test after 21 days. Of course, this study does not decouple the effects of testing from spacing or expansion, but the results do clearly indicate considerable learning and retention using the expanded repeated testing procedure. Spitzer concluded that “...examinations are learning devices and should not be considered only as tools for measuring achievement of pupils” (p. 656, italics added)"

This covers a pretty broad range of what one might call 'declarative' knowledge. Extending testing to other fields is more difficult and may reduce to 'write many frequent analyses, not large ones' or 'do lots of small exercises', whatever those might mean in those fields:

> "A third issue, which relates to the second, is whether our proposal of testing is really appropriate for courses with complex subject matters, such as the philosophy of Spinoza, Shakespeare’s comedies, or creative writing. Certainly, we agree that most forms of objective testing would be difficult in these sorts of courses, but we do believe the general philosophy of testing (broadly speaking) would hold—students should be continually engaged and challenged by the subject matter, and there should not be merely a midterm and final exam (even if they are essay exams). Students in a course on Spinoza might be assigned specific readings and thought-provoking essay questions to complete every week. This would be a transfer-appropriate form of weekly ‘‘testing’’ (albeit with take-home exams). Continuous testing requires students to continuously engage themselves in a course; they cannot coast until near a midterm exam and a final exam and begin studying only then."^[Roediger & Karpicke 2006b again.]

#### Downsides

Testing does have some known flaws:

1. interference in recall - ability to remember tested items drives out ability to remember similar untested items

    Most/all studies were in laboratory settings and found relatively small effects:

    > "In sum, although various types of recall interference are quite real (and quite interesting) phenomena, we do not believe that they compromise the notion of test-enhanced learning. At worst, interference of this sort might dampen positive testing effects somewhat. However, the positive effects of testing are often so large that in most circumstances they will overwhelm the relatively modest interference effects."
2. multiple choice tests can accidentally lead to 'negative suggestion effects' where having previously seen a falsehood as an item on the test makes one more likely to believe it.

    This is mitigated or eliminated when there's quick feedback about the right answer (see Butler & Roediger 2008 ["Feedback enhances the positive effects and reduces the negative effects of multiple-choice testing"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Butler-Feedback-enhances-the-positive-effects.pdf)). Solution: don't use multiple choice; inferior in testing ability to free recall or short answers, anyway.

Neither problem seems major.

### Distributed

A lot depends *when* you do all your testing. Above we saw some benefits to testing a lot the moment you learn something, but the same number of tests could be spread out over time, to give us the *spacing effect* or *spaced repetition*. There are hundreds of studies involving the spacing effect^[For example, [Cepeda 2006](http://uweb.cas.usf.edu/~drohrer/pdfs/Cepeda_et_al_2006PsychBull.pdf) is a review of 184 articles with 317 experiments.], and almost unanimously they find spacing out tests is superior to massed testing when the final test/measurement is conducted days or years later[^superiority], although the mechanism isn't clear[^mechanism]. Besides all the previously mentioned studies, we can throw in:

- Peterson, L. R., Wampler, R., Kirkpatrick, M., & Saltzman, D. (1963). ["Effect of spacing presentations on retention of a paired associate over short intervals"](http://www.sciencedirect.com/science/article/pii/S0022101507648861). _Journal of Experimental Psychology_, 66(2), 206–209
- Glenberg, A. M. (1977). ["Influences of retrieval processes on the spacing effect in free recall"](http://www.sciencedirect.com/science/article/pii/S0096151507602254). _Journal of Experimental Psychology: Human Learning and Memory_, 3(3), 282–294
- Balota, D. A., Duchek, J. M., & Paullin, R. (1989). ["Age-related differences in the impact of spacing, lag and retention interval"](http://www.artsci.wustl.edu/~dbalota/Age%20related%20differences%20in%20the%20impact%20of%20spacing%20Balota%20Duchek%20Paullin.pdf). _Psychology and Aging_, 4, 3–9

[^mechanism]: The Balota review offers a synthesis of current theories on how massed and spaced differ, based on [memory encoding](!Wikipedia "Encoding (memory)"):

    > "According to encoding variability theory, performance on a memory test is dependent upon the overlap between the contextual information available at the time of test and the contextual information available during encoding. During massed study, there is relatively little time for contextual elements to fluctuate between presentations and so this condition produces the highest performance in an immediate memory test, when the test context strongly overlaps with the same contextual information encoded during both of the massed presentations. In contrast, when there is spacing between the items, there is time for fluctuation to take place between the presentations during study, and hence there is an increased likelihood of having multiple unique contexts encoded. Because a delayed test will also allow fluctuation of context, it is better to have multiple unique contexts encoded, as in the spaced presentation format, as opposed to a single encoded context, as in the massed presentation format."

The research literature focuses *extensively* on the question of *what kind* of spacing is best and what this implies about memory: a spacing that has static fixed intervals or a spacing which expands? This is very important for understanding memory and building models of it. But for practical purposes, this is very uninteresting; to sum it up, there are many studies pointing each way, and whatever difference in efficiency exists, is minimal. Most existing software follows SuperMemo in using an expanding spacing algorithm, so it's not worth worrying about; as Mnemosyne developer Peter Bienstman says, it's not clear the more complex algorithms really help[^bienstman]. So too here.

[^superiority]: Balota review:

    > "No feedback or correction was given to subjects if they made errors or omitted answers. Landauer and Bjork found that the expanding-interval schedule produced better recall than equal-interval testing on a final test at the end of the session, and equal-interval testing, in turn, produced better recall than did initial massed testing. Thus, despite the fact that massed testing produced nearly errorless performance during the acquisition phase, the other two schedules produced better retention on the final test given at the end of the session. However, the difference favoring the expanding retrieval schedule over the equal-interval schedule was fairly small at around 10%. In research following up Landauer and Bjork’s (1978) original experiments, practically all studies have found that spaced schedules of retrieval (whether equal-interval or expanding schedules) produce better retention on a final test given later than do massed retrieval tests given immediately after presentation (e.g., Cull, 2000; Cull, Shaughnessy, & Zechmeister, 1996), although exceptions do exist. For example, in Experiments 3 and 4 of Cull et al. (1996), massed testing produced performance as good as equal-interval testing on a 5-5-5 schedule, but most other experiments have found that any spaced schedule of testing (either equal-interval or expanding) is better than a massed schedule for performance on a delayed test. However, whether expanding schedules are better than equal-interval schedules for long-term retention—the other part of Landauer and Bjork’s interesting findings—remains an open question. Balota, Duchek, and Logan (in press) have provided a thorough consideration of the relevant evidence and have shown that it is mixed at best, and that most researchers have found no difference between the two schedules of testing. That is, performance on a final test at the end of a session often shows no difference in performance between equal-interval and expanding retrieval schedules."

    Cull, for those curious (Cull, W. L. (2000). ["Untangling the benefits of multiple study opportunities and repeated testing for cued recall"](http://www.mendeley.com/research/untangling-benefits-multiple-study-opportunities-repeated-testing-cued-recall/). _Applied Cognitive Psychology_, 14, 215–235):

    > "Cull (2000) compared expanded retrieval to equal interval spaced retrieval in a series of four experiments designed to mimic typical teaching or study strategies encountered by students. He examined the role of testing versus simply restudying the material, feedback, and various retention intervals on final test performance. Paired associates (an uncommon word paired with a common word, such as bairn–print) were presented in a manner similar to the flashcard techniques students often use to learn vocabulary words. The intervals between retrieval attempts of to-be-learned information ranged from minutes in some experiments to days in others. Interestingly, across four experiments, Cull did not find any evidence of an advantage of an expanded condition over a uniform spaced condition (i.e., no significant expanded retrieval effect), although both conditions consistently produced large advantages over massed presentations. He concluded that distributed testing of any kind, expanded or equal interval, can be an effective learning aid for teachers to provide for their students."
[^bienstman]: From Mnemosyne's [Principles](http://www.mnemosyne-proj.org/principles.php) page:

    > "The Mnemosyne algorithm is very similar to [SM2](http://www.supermemo.com/english/ol/sm2.htm) used in one of the early versions of SuperMemo. There are some modifications that deal with early and late repetitions, and also to add a small, healthy dose of randomness to the intervals.
    >
    > Supermemo now uses SM11. However, we are a bit skeptical that the huge complexity of the newer SM algorithms provides for a statistically relevant benefit. But, that is one of the facts we hope to find out with our data collection.
    >
    > We will only make modifications to our algorithms based on common sense or if the data tells us that there is a statistically relevant reason to do so."

For those interested, 3 of the studies that found fixed spacings better than expanding:

1. Carpenter, S. K., & DeLosh, E. L. (2005). ["Application of the testing and spacing effects to name learning"](http://www.psychology.iastate.edu/~shacarp/Carpenter_DeLosh_2005.pdf). _Applied Cognitive Psychology_, 19, 619–636[^carpenter]
2. Logan, J. M. (2004). _Spaced and expanded retrieval effects in younger and older adults_. Unpublished doctoral dissertation, Washington University, St. Louis, MO

    This thesis is interesting inasmuch as Logan found that young adults did considerably worse with an expanding spacing after a day.
3. Karpicke & Roediger, 2006a

The fixed vs expanding issue aside, a list of additional generic studies finding benefits to spaced vs massed:

- [Cepeda et al. 2006](http://commonsenseatheism.com/wp-content/uploads/2011/01/Cepeda-Distributed-Practice-in-Verbal-Recall-Trasks.pdf) (large review used elsewhere in this page)
- Karpicke & Roediger 2006a
- Rohrer & Taylor 2006. ["The effects of over-learning and distributed practice on the retention of mathematics knowledge"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Rohrer-The-Effect-of-Overlearning-on-Long-Term-Retention.pdf). _Applied Cognitive Psychology_, 20: 1209-1224.
- Seabrook et al 2005. ["Distributed and Massed Practice: From Laboratory to Classroom"](http://commonsenseatheism.com/wp-content/uploads/2011/01/Saebrook-Distributed-and-massed-practice-From-laboratory-to-classroom.pdf)
- Keppel, Geoffrey. ["A Reconsideration of the Extinction-Recovery Theory"](http://www.sciencedirect.com/science/article/pii/S0022537167800045). _Journal of Verbal Learning & Verbal Behavior_. 6(4) 1967, 476-486

    A week later, the massed reviewers went from 5.9 correct ~> 2.1; the spaced reviewers went from 5.5 ~> 5.0. (Note the usual observation: massed was initially better, and later much worse, less than half as good.)
- Bloom, Kristine C; Shuell, Thomas J. ["Effects of massed and distributed practice on the learning and retention of second-language vocabulary"](http://www.jstor.org/pss/27539823). _Journal of Educational Research_. Vol 74(4) Mar-Apr 1981, 245-248.

    Four days after the 2 groups memorized 16 French words, the spaced group remembered 15 and the massed 11.
Rea, Cornelius P; Modigliani, Vito. ["The effect of expanded versus massed practice on the retention of multiplication facts and spelling lists"](http://psycnet.apa.org/?&fa=main.doiLanding&uid=1986-07610-001). _Human Learning: Journal of Practical Research & Applications_. Vol 4(1) Jan-Mar 1985, 11-18[^multiplication]

    > "A test immediately following the training showed superior performance for the distributed group (70 percent correct) compared to the massed group (53 percent correct). These results seem to show that the spacing effect applies to school-age children and to at least some types of materials that are typically taught in school."^[[Balota et al](http://www.psych.wustl.edu/coglab/publications/Balota+et+al+roddy+chapter.pdf).]
- Donovan, John J; Radosevich, David J. ["A meta-analytic review of the distribution of practice effect: Now you see it, now you don't"](http://doi.apa.org/journals/apl/84/5/795.pdf). _Journal of Applied Psychology_. Vol 84(5) Oct 1999, 795-805

    > "According to Donovan and Radosevich's meta-analysis of spacing studies, the [effect size](!Wikipedia) for the spacing effect is d = .42. This means that the average person getting distributed training remembers better than about 67 percent of the people getting massed training. This effect size is nothing to sneeze at—in education research, effect sizes as low as d = .25 are considered practically significant, while effect sizes above d = 1 are rare."^[Balota et al]

    The meta-analysis notes that the effect size is smaller in studies with better methodology, but still significant.
- Bahrick, Harry P; Phelphs, Elizabeth. ["Retention of Spanish vocabulary over 8 years"](http://www.sciencedirect.com/science/article/pii/S0278739303015805). _Journal of Experimental Psychology: Learning, Memory, & Cognition_. Vol 13(2) Apr 1987, 344-349; the extremely long delay after the initial training period makes this particularly interesting:

    > Harry Bahrick and Elizabeth Phelps (1987) examined the retention of 50 Spanish vocabulary words after an eight-year delay. Subjects were divided into three groups. Each practiced for seven or eight sessions, separated by a few minutes, a day, or 30 days. In each session, subjects practiced until they could produce the list perfectly one time....Eight years later, people in the no-delay group could recall 6 percent of the words, people in the one-day delay group could remember 8 percent, and those in the 30-day group averaged 15 percent. Everyone also took a multiple choice test, and again, the spacing effect was observed. The no-delay group scored 71 percent, the one-day group scored 80 percent, and the 30-day group scored 83 percent.
    >
    > ...Bahrick and his colleagues varied both the spacing of practice and the amount of practice. Practice sessions were spaced 14, 28, or 56 days apart, and totaled 13 or 26 sessions. They tested subjects' memory one, two, three, and five years after training. Once again, it took a bit longer to reach the criterion within each session when practice sessions were spaced farther apart, but again, this small investment paid dividends years later. It didn't matter whether testing occurred at one, two, three, or five years after practice—the 56-day group always remembered the most, the 28-day group was next, and the 14-day group remembered the least. Further, the effect was quite large. If words were practiced every 14 days, you needed twice as much practice to reach the same level of performance as when words were practiced every 56 days!
- Pashler et al., 2003; ["Is Temporal Spacing of Tests Helpful Even When It Inflates Error Rates?"](http://www.pashler.com/Articles/Pashler_Zarow_Triplett03.pdf)

    Long intervals between tests necessarily means you will often err; errors were thought to intrinsically reduce learning. While the extra errors do damage accuracy in the short-run, the long intervals are powerful enough that they still win.
- works on short-term review conducted with Alzheimer's patients; spacing used on the scale of seconds and minutes, with modest success in teaching object locations or daily tasks to do[^calendar]:

    - Camp, C. J. (1989). "Facilitation of new learning in Alzheimer's disease". In G. C. Gilmore, P. J. Whitehouse, & M. L. Wykle (Eds.), _Memory, aging, and dementia_ (pp. 212–225)
    - Camp, C. J., & McKitrick, L. A. (1992). "Memory interventions in Alzheimer's-type dementia populations: Methodological and theoretical issues". In R. L. West & J. D. Sinnott (Eds.), _Everyday memory and aging: Current research and methodology_ (pp. 152–172)

[^carpenter]: Balota:

    > Carpenter and DeLosh (2005, Exp. 2) have recently investigated face-name learning under massed, expanded (1-3-5), and equal interval (3-3-3) conditions. This study also involved study and study and test procedures during the acquisition phase. Carpenter and DeLosh found a large effect of spacing, but no evidence of a benefit of expanded over equal interval practice. In fact, Carpenter and DeLosh reported a reliable benefit of the equal interval condition over the expanded retrieval condition.
[^multiplication]: Balota again:

    > "Rea and Modigliani (1985) tested the effectiveness of expanded retrieval in a third-grade classroom setting. In separate conditions, students were given new multiplication problems or spelling words to learn. The problem or word was presented audiovisually once and then tested on either a massed retrieval schedule of 0-0-0-0 or an expanding schedule of 0-1-2-4, in which the intervals involved being tested on old items or learning new items. After each test trial for a given item, the item was re-presented in its entirety so students received feedback on what they were learning. Performance during the learning phase was at 100% for both spelling words and multiplication facts. On an immediate final retention test, Rea and Modigliani found a performance advantage for all items—math and spelling— practiced on an expanding schedule compared to the massed retrieval schedule. They suggested, as have others, that spacing combined with the high success rate inherent in the expanded retrieval schedule produced better retention than massed retrieval practice. However, as in Spitzer’s study, Rea and Modigliani did not test an appropriate equal interval spacing condition. Hence, their finding that expanded retrieval is superior to massed retrieval in third graders could simply reflect the superiority of spaced versus massed rehearsal—in other words, the spacing effect."
[^calendar]: Balota:

    > "...long-term retention of information has been demonstrated over several days in some cases (e.g., Camp et al., 1996). For example, in the latter study, Camp et al. employed an expanding retrieval strategy to train 23 individuals with mild to moderate AD to refer to a daily calendar as a cue to remember to perform various personal activities (e.g., take medication). Following a baseline phase to determine whether subjects would spontaneously use the calendar, spaced retrieval training was implemented by repeatedly asking the subject the question, “How are you going to remember what to do each day?” at expanding time intervals. The results indicated that 20/23 subjects did learn the strategy (i.e., to look at the calendar) and retained it over a 1-week period."

#### Generality of spacing effect

Spacing effects can be found in:

- various "domains (e.g., learning perceptual motor tasks^[It should be noted that reviews directly conflict on motor skills; Lee and Genovese 1988 find benefits, while Adams 1987 and earlier do not.] vs. learning lists of words)"^[See [Cepeda 2006](http://uweb.cas.usf.edu/~drohrer/pdfs/Cepeda_et_al_2006PsychBull.pdf)]
- "across species (e.g., rats, pigeons, and humans)"
- "across age groups and individuals with different memory impairments"
- "and across retention intervals of seconds to months"

The domains are limited, however. Cepeda 2006:

> "[[Moss 1996](http://psycnet.apa.org/psycinfo/1996-95005-375), reviewing 120 articles] concluded that longer ISIs facilitate learning of verbal information (e.g., spelling) and motor skills (e.g., mirror tracing); in each case, over 80% of studies showed a distributed practice benefit. In contrast, only one third of intellectual skill (e.g., math computation) studies showed a benefit from distributed practice, and half showed no effect from distributed practice.
>
> ...[Donovan and Radosevich (1999)] The largest effect sizes were seen in low rigor studies with low complexity tasks (e.g., rotary pursuit, typing, and peg reversal), and retention interval failed to influence effect size. The only interaction Donovan and Radosevich examined was the interaction of ISI and task domain. It is important to note that task domain moderated the distributed practice effect; depending on task domain and lag, an increase in ISI either increased or decreased effect size. Overall, Donovan and Radosevich found that increasingly distributed practice resulted in larger effect sizes for verbal tasks like free recall, foreign language, and verbal discrimination, but these tasks also showed an inverse-U function, such that very long lags produced smaller effect sizes. In contrast, increased lags produced smaller effect sizes for skill tasks like typing, gymnastics, and music performance."

Skills like gymnastics and music performance raise an important point about the testing effect and spaced repetition: they are for the maintenance of memories or skills, they do not increase it beyond what was already learned. If one is a gifted amateur when one starts reviewing, one remains a gifted amateur. Ericsson covers what is necessary to *improve* and attain new expertise: [deliberate practice](!Wikipedia)^[The famous '10,000 hours of practice' figure may not be as true or important as Ericsson and publicizers like Malcolm Gladwell imply, given the high [variance](!Wikipedia) of expertise against time, and results from sports showing [significantly smaller](http://www.sportsscientists.com/2011/08/talent-training-and-performance-secrets.html) time investments, but the insight of 'deliberate practice' seems real. One may be able to get away with 3,000 hours rather than 10,000, but one isn't going to do that with mindless repetition or no repetitions.]. From ["The Role of Deliberate Practice"](/docs/1993-ericsson-deliberatepractice.pdf):

> "The view that merely engaging in a sufficient amount of practice - regardless of the structure of that practice - leads to maximal performance, has a long and contested history. In their classic studies of Morse Code operators, Bryan and Harter (1897, 1899) identified plateaus in skill acquisition, when for long periods subjects seemed unable to attain further improvements. However, with extended efforts, subjects could restructure their skill to overcome plateaus....Even very experienced Morse Code operators could be encouraged to dramatically increase their performance through deliberate efforts when further improvements were required...More generally, Thorndike (1921) observed that adults perform at a level far from their maximal level even for tasks they frequently carry out. For instance, adults tend to write more slowly and illegibly than they are capable of doing....The most cited condition [for optimal learning and improvement of performance] concerns the subjects' motivation to attend to the task and exert effort to improve their performance....The subjects should receive immediate informative feedback and knowledge of results of their performance....In the absence of adequate feedback, efficient learning is impossible and improvement only minimal even for highly motivated subjects. Hence mere repetition of an activity will not automatically lead to improvement in, especially, accuracy of performance...In contrast to play, deliberate practice is a highly structured activity, the explicit goal of which is to improve performance. Specific tasks are invented to overcome weaknesses, and performance is carefully monitored to provide cues for ways to improve it further. We claim that deliberate practice requires effort and is not inherently enjoyable."

### Review summary

To bring it all together with the gist:

- testing is very effective and comes with minimal [negative factors](#downsides)
- expanding spacing is roughly as good as or better than (wide) fixed intervals, but expanding is more convenient and the default
- testing (and hence spacing) is best on intellectual, highly factual, verbal domains, but may still work in many low-level domains
- the research favors questions which force the user to use their memory as much as possible; in descending order of preference:

    1. free recall
    2. short answers
    3. multiple-choice
    4. Cloze deletion
    5. recognition
- the research literature is comprehensive and most questions have been answered - somewhere.
- the most common mistake2 with spaced repetition is 1) formulating poor questions and answers; and 2) assuming it will help you learn, as opposed to maintain and preserve what one already learned. (It's hard to learn *from* cards, but if you have learned something, it's much easier to then devise a set of flashcards that will test your weak points.)

## Using it

One doesn't need to use SuperMemo, of course; there are plenty of free alternatives. I like [Mnemosyne](!Wikipedia "Mnemosyne (software)") ([homepage](http://www.mnemosyne-proj.org/)) myself - [Free](!Wikipedia "Free software"), packaged for [Ubuntu Linux](!Wikipedia), and quite easy to use.

OK, but what does one do with it? It's a surprisingly difficult question, actually. It's akin to "the  tyranny of the blank page" (or blank wiki); now that I have all this power - a mechanical golem that will never forget and never let me forget whatever I chose to - what do I choose to remember?

### Problems

One common experience of new users to spaced repetition is to add too much stuff - trivialities and things they don't really care about. But they soon learn the curse of [Borges's](!Wikipedia "Jorge Luis Borges") [Funes the Memorious](!Wikipedia). If they don't actually want to learn the material they put in, they will soon stop doing the daily reviews - which will cause reviews to pile up, which will be further discouraging, and so they stop. At least with physical fitness there isn't a precisely dismaying number indicating how far behind you are! But if you have too little at the beginning, you'll have few repetitions per day, and you'll see no obvious benefit from the technique itself - it looks just like boring flash card review.

### What to add

The most difficult task, beyond that of just persisting until the benefits do become obvious, is deciding what's valuable enough to add in. In a 3 year period, one can expect to spend "30-40 seconds"^[["SuperMemo as a new tool increasing the productivity of a programmer. A case study: programming in Object Windows"](http://www.supermemo.com/articles/programming.htm)] on any given item. The long run [theoretical predictions](http://www.supermemo.com/articles/theory.htm) are a little hairier. Given a single item, the formula for daily time spent on it is $\text{time} = \frac{1}{500} \times \text{nthYear}^{-1.5} + \frac{1}{30000}$. So over 20 years, we would spend $t = \frac{1}{500} \times 20^{-1.5} + \frac{1}{3000}$, or `3.556940131083312e-4` minutes a day. To convert it to *total* time over those 20 years, we simply multiply by however many days are in those 20 years, so the relevant Haskell would be:

~~~{.haskell}
((1/500 * 20**(-(1.5))) + 1/3000) * (20*365.25)
~~~

Which evaluates to 2.6 minutes. But maybe [Piotr Woźniak](!Wikipedia "Piotr Woźniak (researcher)") was being optimistic or we're bad at [writing flashcards](http://www.supermemo.com/articles/20rules.htm), so we'll double it to 5 minutes. That's our key rule of thumb that lets us decide what to learn and what to forget: if, over your lifetime, you will spend more than 5 minutes looking something up or will lose more than 5 minutes as a result of not knowing something, then it's worthwhile to memorize it with spaced repetition. 5 minutes is the line that divides trivia from useful data.[^memorizing] (There might seem to be thousands of flashcards that meet the 5 minute rule. That's fine. Spaced repetition can accommodate dozens of thousands of cards. See the [next section](#the-workload).)

To a lesser extent, one might wonder when one is in a hurry, should one learn something with spaced repetition and with massed? How far away should the tests or deadlines be before abandoning spaced repetition? It's hard to compare since one would need a specific regimens to compare for the crossover point, but for massed repetition, the average time after memorization at which one has a 50% chance of remembering the memorized item seems to be 3-5 days.^[See Stephen R. Schmidt's webpage ["Theories of Forgetting"](http://frank.itlab.us/forgetting/mtsu_forgetting/#II.%20Decay%20Theory), which cites 'Woodworth & Schlosbeg (1961)' when presenting a [log graph](http://frank.itlab.us/forgetting/mtsu_forgetting/woodworth.jpg) of various studies' forgetting curves.] Since there would be 2 or 3 repetitions in that period, presumably one would do better than 50% in recalling an item. 5 minutes and 5 days seems like a memorable enough rule of thumb: 'don't use spaced repetition if you need it sooner than 5 days or it's worth less than 5 minutes'.

I find one of the best uses for Mnemosyne is, besides adding questions relating to class material, to add in words from [A Word A Day](!Wikipedia)^[which neatly addresses the issue of such mailing lists being useless ('who learns a word after just one exposure?').] and [Wiktionary](!Wikipedia), memorable quotes I see^[Mnemosyne in this case constitutes both a way to learn the quotes so I can use them, and a [waste book](!Wikipedia "Notebook (style)"); just the other day I had 3 or 4 apposite quotes for an essay because I had entered them into Mnemosyne months or years ago.], personal information such as birthdays ^[I could never remember my license plate number until I entered 3 or 4 questions [anent](http://www.google.com/search?q=define%3Aanent)'t into Mnemosyne.], and so on. Quotidian uses, but valuable to me. With a diversity of flashcards, I find my daily review interesting. I get all sorts of questions - now I'm trying to see whether a Haskell fragment is syntactically correct, now I'm pronouncing Korean hangul aloud and listening to the answer, now I'm trying to find the Ukraine on a map, now I'm enjoying some A.E. Houseman poetry, followed by a few quotes from LessWrong quotes threads, and so on.

### The workload

On average, when I'm studying a new topic, I'll add 3-20 questions a day. Combined with my particular memory, I usually review about 90 or 100 items a day (out of the total >18,300). This takes under 20 minutes, which is not too bad. (I expect the time is expanded a bit by the fact that early on, my formatting guidelines were still being developed, and I hadn't the full panoply of categories I do not - so every so often in a review I must stop and do some editing.)

If I haven't been studying something recently, the exponential back off of reviews slowly drops the daily review. For example, in March 2011, I wasn't studying very many things, so for 24-26 March 2011, my scheduled daily reviews are 73, 83, and 74; after that, it'll probably drop down into the 60s, and then after another week or two, into the 50s and so on until it hits the minimum plateau which will very slowly shrink over years. (I haven't gone long enough without dumping cards in to know what that might be.)

If Mnemosyne weren't using spaced repetition, it would be very hard to keep up with 18,300+ flashcards. But because it is using spaced repetition, keeping up is very easy. (Nor is 18.3k extraordinary. Many users have decks in the 6-7k range, Mnemosyne developer [Peter Bienstman](http://groups.google.com/group/mnemosyne-proj-users/browse_frm/thread/433872b155ad7451/31c1e4c556680a0c) has >8.5k & Patrick Kenny >27k, [Hugh Chen](http://groups.google.com/group/mnemosyne-proj-users/browse_frm/thread/eff44f5fdb1d738b/7a7b654ca87e63be) has a 73k+ deck, and in [#anki](irc://irc.freenode.net#anki), they tell me of one user who triggered bugs with his >200k deck.)

### When to review

When should one review? In the morning? In the evening? Any old time? The studies demonstrating the spacing effect do not control or vary the time of day, so in one sense, the answer is: it doesn't matter - if it did matter, there would be considerable variance in how effective the effect is based on when a particular study had its subjects do their reviews.

So one reviews at whatever time is convenient. Convenience makes one more likely to stick with it, and sticking with it overpowers any temporary improvement.

If one is not satisfied with that answer, then on general considerations, one ought to review before bedtime & sleep.

[Memory consolidation](!Wikipedia "Memory consolidation#Spacing Effect") seems to be related, and [sleep](!Wikipedia "Sleep and memory") is known to powerfully influence what memories enter long-term memory; interrupting sleep without affecting total sleep time or quality still [damages memory formation in mice](http://www.pnas.org/content/early/2011/07/20/1015633108)[^polyphasic]. So reviewing before bedtime would be best. (Other mental exercises show improvement when trained before bedtime; for example, [dual n-back](DNB FAQ#sleep).) One possible mechanism is that it may be that the [*expectancy*](http://www.jneurosci.org/content/31/5/1563.short) of future reviews/tests is enough to encourage memory consolidation during sleep; so if one reviews and goes to bed, presumably the expectancy is stronger than if one reviewed at breakfast and had an eventful day and forgot entirely about the reviewed flashcards.

[^polyphasic]: In this vein, I am reminded of what a former [polyphasic sleeper](!Wikipedia "Polyphasic sleep") [told](http://lesswrong.com/lw/5n0/optimizing_sleep/44wz) [me](http://lesswrong.com/lw/5n0/optimizing_sleep/4509):

    > "I've been polyphasic for about a year. (Not anymore; kills my memory.)...Anki reps, mostly. I found that I could do proper review sessions for about 2-3 days and would hit an impenetrable wall. I couldn't learn a single new card and had total brain fog until I got 3 hours more sleep. That, however, would reset my adaptation. The whole effect is a bit less pronounced on Everyman, but not much. It is however easier to add sleep when you already have a core. I didn't notice any other major mental impairment after the initial sleep deprivation."

#### Prospects: extended flashcards

Let's step back for a moment. What are all our flashcards, small and large, doing for us? Why do I have a pair of flashcards for the word 'anent' among many others? I can just look it up.

But look ups take time compared to already knowing something. (Let's ignore the previously discussed 5 minute rule.) If we think about this abstractly in a computer science context, we might recognize it as an old concept in algorithms & optimization discussions - the [space-time tradeoff](!Wikipedia). We trade off lookup time against limited skull space.

The most obvious example is the sort of factual data already given as examples - we might one day need to know the average annual rainfall in Honolulu or Austin, but it would require too much space to memorize such data for all capitals. There are millions of English words, but in practice any more than 100,000 is excessive.

Less obvious is a sort of procedural knowledge. An extreme form of space-time tradeoffs in computers is when a computation is replaced by pre-calculated constants. We could take a math [function](!Wikipedia "Function (mathematics)") and calculate its output for each possible input. Usually such a [lookup table](!Wikipedia) of input to output is really large. Think about how many entries would be in such a table for all possible integer multiplications between 1 and 1 billion. But sometimes the table is really small (like binary Boolean functions) or small (like trigonometric tables) or very large but still useful ([rainbow table](!Wikipedia)s usually start in the gigabytes and easily reach terabytes).

Given an infinitely large lookup table, we could replace *completely* the skill of, say, addition or multiplication by the lookup table. No computation. The space-time tradeoff taken to the extreme of the space side of the continuum. (We could go the other way and define multiplication or addition as the very slow computation which doesn't know any specifics like the [multiplication table](!Wikipedia) - as if every time you wanted to add $2+2$ you had to count on 4 fingers.)

So suppose we were children who wanted to learn multiplication. SRS and Mnemosyne can't help because multiplication is not a specific factoid? The space-time tradeoff shows us that we can de-proceduralize multiplication and turn it partly into factoids. It wouldn't be hard for us to write a quick script or macro to generate, say, 500 random cards which ask us to multiply AB by XY, and import them to Mnemosyne.^[Presumably one would immediately give them all some high grade like 5 to avoid suddenly having a daily load of 500 cards for a while.]

After all, which is your mind going to do - get good at multiplying 2 numbers (generate on-demand), or memorize 500 different multiplication problems ([memoize](!Wikipedia))? From my experience with multiple subtle variants on a card, the mind gives up after just a few and falls back on a problem-solving approach
- which is exactly what one wants to exercise, in this case. Congratulations; you have done the impossible.

From a software engineering point of view, we might want to modify or improve the cards, and 500 snippets of text would be a tad hard to update. So coolest would be a 'dynamic card'. Add a markup type like `<eval src="">`  , and then Mnemosyne feeds the `src` argument straight into the Python interpreter, which returns a [tuple](!Wikipedia) of the question text and the answer text. The question text is displayed to the user as usual, the user thinks, requests the answer, and grades himself.

So for multiplication, the dynamic card would get 2 random integers, print a question like 'x * y = ?' and then print x*y as the answer. Every so often you would get a new multiplication question, and as you get better at multiplication, you see it less often - exactly as you should. Still in a [math vein](http://www.reddit.com/r/math/comments/hvqzd/printable_math_flashcards_in_pdf_and_latex_source/c1yror5), you could generate variants on formulas or programs where one version is the correct one and the others are subtly wrong; I do this by hand with my programming flashcards (especially if I make an error doing exercises, that signals a finer point to make several flashcards on), but it can be done automatically. [kpreid](http://lesswrong.com/lw/64k/memory_spaced_repetition_and_life/4e5n) [describes](http://lesswrong.com/lw/64k/memory_spaced_repetition_and_life/4e5n) one tool of his:

> "I have written [a program](https://github.com/kpreid/mathquiz/) (in the form of [a web page](http://kpreid.github.com/mathquiz/mathquiz.html)) which does a specialized form of this [generating 'damaged formulas']. It has a set of generators of formulas and damaged formulas, and presents you with a list containing several formulas of the same type (e.g. ∫ 2x dx = x^2 + C) but with one damaged (e.g. ∫ 2x dx = 2x^2 + C)."

This approach generalizes to anything you can generate random problems of or have large databases of examples of. For example, maybe you are studying Go and are interested in learning [life-and-death positions](!Wikipedia "Life and death"). Those are things that can be generated by computer Go programs, or fetched from places like <http://www.goproblems.com/>. For even more examples, Go is rotationally invariant - the best move remains the same regardless of which way the board is oriented and since there is no canonical direction for the board (like in chess) a good player ought to be able to play the same no matter how the board looks - so each specific example can be mirrored in 3 other ways. Or one could test one's ability to 'read' a board by writing a dynamic card which takes each example board/problem and adds some random pieces as long as some go-playing program like [GNU Go](!Wikipedia) says the best move hasn't changed because of the added noise.

One could learn an awful lot of things this way. Programming languages could be learned this way - someone learning [Haskell](!Wikipedia "Haskell (programming language)") could take all the functions listed in the Prelude or his Haskell textbook, and ask [QuickCheck](!Wikipedia) to generate random arguments for the functions and ask the [GHC](!Wikipedia "Glasgow Haskell Compiler") interpreter `ghci` what the function and its arguments evaluate to. Games other than go, like chess. A fair bit of mathematics. If the dynamic card has Internet access, it can pull down fresh questions from an [RSS feed](!Wikipedia) or just a website; this functionality could be quite useful in a foreign language learning context with every day bringing a fresh sentence to translate or another exercise.

Even though these things seem like 'skills' and not 'data'!

# Popularity

-----------------------------------------------------------------------------------------------------------
 Metric[^date]       Mnemosyne          [Mnemododo][] [Anki][]                iSRS        [AnyMemo][]
---------------    -------------------- ---------     ----------       --------------    ------------------
 Homepage Alexa    [383k][]             [27.5m][]     [112k][]                           [1,766k][][^alexa]

 ML/forum members  [461][]                            [4129][]/[215][] [129][]           [119][]

 Ubuntu installs   [7k][]                             [9k][]

 Debian installs   [164][]                            [364][]

 Arch votes        [85][]                             [96][]

 iPhone ratings    Unreleased[^imnemo]                [193][]          [69][]

 Android ratings                        [20][]        [703][]                            [836][]

 Android installs                       [100-500][]   [10-50k][]                         [50-100k][FANTASTIC]
--------------------------------------------------------------------------------------------------------------

[Mnemododo]: http://www.tbrk.org/software/mnemododo.html
[Anki]: http://en.wikipedia.org/wiki/Anki
[AnyMemo]: http://anymemo.org/
[383k]: http://www.alexa.com/siteinfo/mnemosyne-proj.org
[112k]: http://www.alexa.com/siteinfo/ankisrs.net#
[27.5m]: http://www.alexa.com/siteinfo/tbrk.org#
[1,766k]: http://www.alexa.com/siteinfo/anymemo.org#
[461]: http://groups.google.com/group/mnemosyne-proj-users
[4129]: http://groups.google.com/group/ankisrs/
[215]: https://groups.google.com/group/ankisrs-users/about
[129]: http://groups.google.com/group/isrs-support
[119]: http://anymemo.org/forum/
[7k]: http://popcon.ubuntu.com/universe/by_inst
[9k]: http://popcon.ubuntu.com/unknown/by_inst
[164]: http://qa.debian.org/popcon.php?package=mnemosyne
[364]: http://qa.debian.org/popcon.php?package=anki
[85]: http://aur.archlinux.org/packages.php?ID=13628
[96]: http://aur.archlinux.org/packages.php?ID=14403
[193]: http://itunes.apple.com/us/app/ankisrs/id373493387
[69]: http://itunes.apple.com/app/isrs-free/id332350042
[20]: https://market.android.com/details?id=org.tbrk.mnemododo
[703]: https://market.android.com/details?id=com.ichi2.anki
[836]: https://market.android.com/details?id=org.liberty.android.fantastischmemo
[100-500]: https://market.android.com/details?id=org.tbrk.mnemododo
[10-50k]: https://market.android.com/details?id=com.ichi2.anki
[FANTASTIC]: https://market.android.com/details?id=org.liberty.android.fantastischmemo

[^date]: All numbers from 2 May 2011.

SuperMemo doesn't fall under the same ratings, but it has sold in the hundreds of thousands over its 2 decades:

> "Biedalak is CEO of SuperMemo World, which sells and licenses Wozniak's invention. Today, SuperMemo World employs just 25 people. The venture capital never came through, and the company never moved to California. About 50,000 copies of SuperMemo were sold in 2006, most for less than $30. Many more are thought to have been pirated."^[[_Wired_](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak?currentPage=5)]

It seems safe to estimate the combined market-share of Anki, Mnemosyne, iSRS and other SRS apps at somewhere under 50,000 users (making due allowance for users who install multiple times, those who install and abandon it, etc.). Relatively few users seem to have migrated from SuperMemo to those newer programs, so it seems fair to simply add that 50k to the other 50k and conclude that the worldwide population is somewhere around (but probably under) 100,000.

[^alexa]: Smaller is better.
[^imnemo]: ["For Mnemosyne 2.x, Ullrich is working on an official Mnemosyne iPhone client which will have very easy syncing."](http://groups.google.com/group/mnemosyne-proj-users/browse_frm/thread/5bbe0fceaef5dab5/83b6f215c918771f)

# Where was I going with this?

Nowhere, really. Mnemosyne/SR software in general are just one of my favorite tools: it's based on a famous effect[^proudest] discovered by science, and it exploits it very elegantly[^me] and usefully. It's a testament to the Enlightenment ideal of improving humanity through reason and overcoming our human flaws; the idea of SR is seductive in its mathematical rigor[^splendor]. In this age where so often the ideal of 'self-improvement' and progress are decried, and gloom are espoused by even the common people, it's really nice to just have a small example like this in one's daily life, an example not yet so prosaic and boring as the lightbulb.

# See also

In the course of using Mnemosyne, I've written a number of scripts to generate repetitively varying cards.

- [mnemo.hs](haskell/mnemo.hs) will take any newline-delimited chunk of text, like a poem, and generates to  every possible [Cloze deletion](!Wikipedia); that is, a ABC poem will become 3 questions: \_BC/ABC, A\_C/ABC, AB\_C/ABC
- [mnemo2.hs](haskell/mnemo2.hs) works as above, but is more limited and is intended for long chunks of text where mnemo.hs would cause a combinatorial explosion of generated questions; it generates a subset: for ABCD, one gets \_\_CD/ABCD, A\_\_D/ABCD, and AB\_\_/ABCD (it removes 2 lines, and iterates through the list).
- [mnemo3.hs](haskell/mnemo3.hs) is intended for date or name-based questions. It'll take input like 'Barack Obama is %47%.' and spit out some questions based on this: 'Barack Obama is \_7./47', 'Barack Obama is 4\_./47' etc.
- [mnemo4.hs](haskell/mnemo4.hs) is intended for long lists of items. If one wants to memorize the list of US Presidents, the natural questions for flashcards goes something like 'Who was the 3rd president?/Thomas Jefferson', 'Thomas Jefferson was the \_rd president./3', 'Who was president after John Adams?/Thomas Jefferson', 'Who was president before James Madison?/Thomas Jefferson'.

    You note there's repetition if you do this for each president - one asks the ordinal position of the item both ways (item -> position, position -> item), what precedes it, and what succeeds it. mnemo4.hs automates this, given a list. In order to be general, the wording is a bit odd, but it's better than writing it all out by hand! (Example output is in the [comments](!Wikipedia "Comment (computer programming)") to the source code).

The reader might well be curious by this point what *my* Mnemosyne database looks like. I use Mnemosyne quite a bit, and as of 23 March 2011, I have 18,327 cards in my deck. Said curious reader may find my database exported as XML at [docs/gwern.xml.gz]().

# External links

- ["Teaching linear algebra"](http://bentilly.blogspot.com/2009/09/teaching-linear-algebra.html) (with spaced repetition), by Ben Tilly
- [AJATT table of contents](http://www.alljapaneseallthetime.com/blog/all-japanese-all-the-time-ajatt-how-to-learn-japanese-on-your-own-having-fun-and-to-fluency) -(applying SRS to learning Japanese)

> "Two psychology journals have recently published papers showing that this strategy works, the latest findings from a decades-old body of research. When students study on their own, "active recall" — recitation, for instance, or flashcards and other self-quizzing — is the most effective way to inscribe something in long-term memory. Yet many college instructors are only dimly familiar with that research..." from ["Close the Book. Recall. Write It Down.: That old study method still works, researchers say. So why don't professors preach it?"](http://chronicle.com/free/v55/i34/34a00101.htm); _[The Chronicle of Higher Education](!Wikipedia)_

## Flashcard sources

- the [Mnemosyne deck collection](http://mnemosyne-proj.org/taxonomy/term/10%208%209%206%207%2011%2012%2013%2028%2014%2015%2016%2017%2018%2019%2020%2021%2022%2023%2024%2025%2026%2027%2029%2030%2031%2032%2040%2039%2034%2035%2036%2037%2041%2042%2046%2047%2050%2049)
- the Anki deck collection is viewable only through the Anki clients; >3000 decks
- [FlashCardExchange.com](http://www.flashcardexchange.com)
- [StudyStack.com](http://www.studystack.com/)
- [AnyMemo](http://anymemo.org/index.php?page=databases) (partially redundant with Mnemosyne & Anki)

[^splendor]: See [page 7](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak?currentPage=7), Wolf 2008

     > "And yet now, as I grin broadly and wave to the gawkers, it occurs to me that the cold rationality of his approach may be only a surface feature and that, when linked to genuine rewards, even the chilliest of systems can have a certain visceral appeal. By projecting the achievement of extreme memory back along the forgetting curve, by provably linking the distant future - when we will know so much - to the few minutes we devote to studying today, Wozniak has found a way to condition his temperament along with his memory. He is making the future noticeable. He is trying not just to learn many things but to warm the process of learning itself with a draft of utopian ecstasy."
[^me]: When I first read of SuperMemo, I had already taken a class in [cognitive psychology](!Wikipedia) and was reasonably familiar with Ebbinghaus's forgetting curve - so my reaction to its methodology was Huxley's: "How extremely stupid not to have thought of that!"
[^proudest]: See [Page 4](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak?currentPage=4), Wolf 2008:

     > "The spacing effect was one of the proudest lab-derived discoveries, and it was interesting precisely because it was not obvious, even to professional teachers. The same year that Neisser revolted, Robert Bjork, working with Thomas Landauer of Bell Labs, published the results of two experiments involving nearly 700 undergraduate students. Landauer and Bjork were looking for the optimal moment to rehearse something so that it would later be remembered. Their results were impressive: The best time to study something is at the moment you are about to forget it. And yet - as Neisser might have predicted - that insight was useless in the real world."
[^wired1]:  "SuperMemo is based on the insight that there is an ideal moment to practice what you've learned. Practice too soon and you waste your time. Practice too late and you've forgotten the material and have to relearn it. The right time to practice is just at the moment you're about to forget. Unfortunately, this moment is different for every person and each bit of information. Imagine a pile of thousands of flash cards. Somewhere in this pile are the ones you should be practicing right now. Which are they?" Gary Wolf, ["Want to Remember Everything You'll Ever Learn? Surrender to This Algorithm"](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak), _[Wired Magazine](!Wikipedia)_
[^memorizing]: modulo things where knowing it is useful even if you don't need it very often - it can be a brick in a pyramid of knowledge; cf. [page 3](http://www.wired.com/medtech/health/magazine/16-05/ff_wozniak?currentPage=3) of Wolf:

     > "The problem of forgetting might not torment us so much if we could only convince ourselves that remembering isn't important. Perhaps the things we learn - words, dates, formulas, historical and biographical details - don't really matter. Facts can be looked up. That's what the Internet is for. When it comes to learning, what really matters is how things fit together. We master the stories, the schemas, the frameworks, the paradigms; we rehearse the lingo; we swim in the episteme.
     >
     > The disadvantage of this comforting notion is that it's false. "The people who criticize memorization - how happy would they be to spell out every letter of every word they read?" asks Robert Bjork, chair of UCLA's psychology department and one of the most eminent memory researchers. After all, Bjork notes, children learn to read whole words through intense practice, and every time we enter a new field we become children again. "You can't escape memorization," he says. "There is an initial process of learning the names of things. That's a stage we all go through. It's all the more important to go through it rapidly." The human brain is a marvel of associative processing, but in order to make associations, data must be loaded into memory."
[^img]: This image is only evocative! I whipped this up in [Inkscape](!Wikipedia) one night; it certainly is not a representation of a real experimental dataset or anything like that.
[^efficiency]: from "The Spacing Effect: A Case Study in the Failure to Apply the Results of Psychological Research" (Frank N. Dempster):

     > "Second, it is remarkably robust. In many cases, two spaced presentations are about twice as effective as two massed presentations (e.g., Hintzman, 1974; Melton, 1970), and the difference between them increases as the frequency of repetition increases (Underwood, 1970)...
     >
     > The spacing effect was known as early as 1885 when Ebbinghaus published the results of his seminal work on memory. With himself as the subject, Ebbinghaus found that for a single 12-syllable series, 68 immediately successive repetitions had the effect of making possible an errorless recital after seven additional repetitions on the following day. However, the same effect was achieved by only 38 distributed repetitions spread over 3 days. On the basis of this and other related findings, Ebbinghaus concluded that 'with any considerable number of repetitions a suitable distribution of them over a space of time is decidedly more advantageous than the massing of them at a single time" (Ebbinghaus, 1885/1913. p. 89)"

     From [_Psychology: An Introduction_](http://www.psywww.com/intropsych/ch06_memory/spacing_effect.html):

     > "In one practical demonstration of the spacing effect, Bahrick, Bahrick, Bahrick, & Bahrick (1993) showed that retention of foreign language vocabulary was greatly enhanced if practice sessions were spaced far apart. For example, "Thirteen retraining sessions spaced at 56 days yielded retention comparable to 26 sessions spaced at 14 days." In other words, subjects could use _half as many study sessions_, if the study sessions were spread over a time period _four times as long_."
[^mapping]: There are many studies to the effect that active recall is best. Here's one recent study, ["Retrieval Practice Produces More Learning than Elaborative Studying with Concept Mapping"](http://www.sciencemag.org/content/early/2011/01/19/science.1199327.abstract), Karpicke 2011 (covered in [_Science Daily_](http://www.sciencedaily.com/releases/2011/01/110121111216.htm) and the [_NYT_](http://www.nytimes.com/2011/01/21/science/21memory.html)):

    > "Educators rely heavily on learning activities that encourage elaborative studying, while activities that require students to practice retrieving and reconstructing knowledge are used less frequently. Here, we show that practicing retrieval produces greater gains in meaningful learning than elaborative studying with concept mapping. The advantage of retrieval practice generalized across texts identical to those commonly found in science education. The advantage of retrieval practice was observed with test questions that assessed comprehension and required students to make inferences. The advantage of retrieval practice occurred even when the criterial test involved creating concept maps. Our findings support the theory that retrieval practice enhances learning by retrieval-specific mechanisms rather than by elaborative study processes. Retrieval practice is an effective tool to promote conceptual learning about science."

    From ["Forget What You Know About Good Study Habits"](http://www.nytimes.com/2010/09/07/health/views/07mind.html). _New York Times_;

    > "Cognitive scientists do not deny that honest-to-goodness cramming can lead to a better grade on a given exam. But hurriedly jam-packing a brain is akin to speed-packing a cheap suitcase, as most students quickly learn — it holds its new load for a while, then most everything falls out....When the neural suitcase is packed carefully and gradually, it holds its contents for far, far longer. An hour of study tonight, an hour on the weekend, another session a week from now: such so-called spacing improves later recall, without requiring students to put in more overall study effort or pay more attention, dozens of studies have found.
    >
    > “The idea is that forgetting is the friend of learning,” said Dr. Kornell. “When you forget something, it allows you to relearn, and do so effectively, the next time you see it.”
    >
    > That’s one reason cognitive scientists see testing itself — or practice tests and quizzes — as a powerful tool of learning, rather than merely assessment. The process of retrieving an idea is not like pulling a book from a shelf; it seems to fundamentally alter the way the information is subsequently stored, making it far more accessible in the future.
    >
    > [In one of his own experiments](http://memory.psych.purdue.edu/downloads/2006_Roediger_Karpicke_PsychSci.pdf), Dr. Roediger and Jeffrey Karpicke, who is now at Purdue University, had college students study science passages from a reading comprehension test, in short study periods. When students studied the same material twice, in back-to-back sessions, they did very well on a test given immediately afterward, then began to forget the material.
    >
    > But if they studied the passage just once and did a practice test in the second session, they did very well on one test two days later, and another given a week later."
